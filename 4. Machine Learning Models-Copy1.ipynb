{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2c8b268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['PropDate'])\n",
    "\n",
    "X = df.drop('PolicyIssued', axis=1)  # Features\n",
    "y = df['PolicyIssued']  # Target variable\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Create new DataFrames for training and testing data\n",
    "df = pd.concat([X_train, y_train], axis=1) # To use for training and validation\n",
    "df_test = pd.concat([X_test, y_test], axis=1) # To use as unseen data on which to test the developed ML model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9b0599",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f767f82f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.78505369        nan 0.78534707        nan 0.78429344\n",
      "        nan 0.78537135        nan 0.78647608]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Hyperparameters and Cross-Validation Scores:\n",
      "Hyperparameters: {'C': 0.001, 'penalty': 'l1'}\n",
      "Mean CV Score: nan\n",
      "Hyperparameters: {'C': 0.001, 'penalty': 'l2'}\n",
      "Mean CV Score: 0.79\n",
      "Hyperparameters: {'C': 0.01, 'penalty': 'l1'}\n",
      "Mean CV Score: nan\n",
      "Hyperparameters: {'C': 0.01, 'penalty': 'l2'}\n",
      "Mean CV Score: 0.79\n",
      "Hyperparameters: {'C': 0.1, 'penalty': 'l1'}\n",
      "Mean CV Score: nan\n",
      "Hyperparameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "Mean CV Score: 0.78\n",
      "Hyperparameters: {'C': 1, 'penalty': 'l1'}\n",
      "Mean CV Score: nan\n",
      "Hyperparameters: {'C': 1, 'penalty': 'l2'}\n",
      "Mean CV Score: 0.79\n",
      "Hyperparameters: {'C': 10, 'penalty': 'l1'}\n",
      "Mean CV Score: nan\n",
      "Hyperparameters: {'C': 10, 'penalty': 'l2'}\n",
      "Mean CV Score: 0.79\n",
      "Best Hyperparameters: {'C': 10, 'penalty': 'l2'}\n",
      "Accuracy: 0.78\n",
      "Precision: 0.79\n",
      "Recall: 0.98\n",
      "F1 Score: 0.88\n",
      "ROC AUC Score: 0.54\n",
      "-------------------------\n",
      "Model: Decision Tree\n",
      "Hyperparameters and Cross-Validation Scores:\n",
      "Hyperparameters: {'max_depth': None, 'min_samples_split': 2}\n",
      "Mean CV Score: 0.69\n",
      "Hyperparameters: {'max_depth': None, 'min_samples_split': 5}\n",
      "Mean CV Score: 0.70\n",
      "Hyperparameters: {'max_depth': None, 'min_samples_split': 10}\n",
      "Mean CV Score: 0.72\n",
      "Hyperparameters: {'max_depth': 10, 'min_samples_split': 2}\n",
      "Mean CV Score: 0.80\n",
      "Hyperparameters: {'max_depth': 10, 'min_samples_split': 5}\n",
      "Mean CV Score: 0.80\n",
      "Hyperparameters: {'max_depth': 10, 'min_samples_split': 10}\n",
      "Mean CV Score: 0.80\n",
      "Hyperparameters: {'max_depth': 20, 'min_samples_split': 2}\n",
      "Mean CV Score: 0.73\n",
      "Hyperparameters: {'max_depth': 20, 'min_samples_split': 5}\n",
      "Mean CV Score: 0.74\n",
      "Hyperparameters: {'max_depth': 20, 'min_samples_split': 10}\n",
      "Mean CV Score: 0.75\n",
      "Hyperparameters: {'max_depth': 30, 'min_samples_split': 2}\n",
      "Mean CV Score: 0.69\n",
      "Hyperparameters: {'max_depth': 30, 'min_samples_split': 5}\n",
      "Mean CV Score: 0.71\n",
      "Hyperparameters: {'max_depth': 30, 'min_samples_split': 10}\n",
      "Mean CV Score: 0.73\n",
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 10}\n",
      "Accuracy: 0.80\n",
      "Precision: 0.81\n",
      "Recall: 0.96\n",
      "F1 Score: 0.88\n",
      "ROC AUC Score: 0.60\n",
      "-------------------------\n",
      "Model: Random Forest\n",
      "Hyperparameters and Cross-Validation Scores:\n",
      "Hyperparameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Mean CV Score: 0.76\n",
      "Hyperparameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Mean CV Score: 0.76\n",
      "Hyperparameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Mean CV Score: 0.76\n",
      "Hyperparameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Mean CV Score: 0.77\n",
      "Hyperparameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Mean CV Score: 0.77\n",
      "Hyperparameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Mean CV Score: 0.77\n",
      "Hyperparameters: {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Mean CV Score: 0.78\n",
      "Hyperparameters: {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Mean CV Score: 0.78\n",
      "Hyperparameters: {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Mean CV Score: 0.78\n",
      "Hyperparameters: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Mean CV Score: 0.79\n",
      "Hyperparameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Mean CV Score: 0.79\n",
      "Hyperparameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Mean CV Score: 0.79\n",
      "Hyperparameters: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Mean CV Score: 0.80\n",
      "Hyperparameters: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Mean CV Score: 0.80\n",
      "Hyperparameters: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Mean CV Score: 0.80\n",
      "Hyperparameters: {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Mean CV Score: 0.80\n",
      "Hyperparameters: {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Mean CV Score: 0.80\n",
      "Hyperparameters: {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Mean CV Score: 0.80\n",
      "Hyperparameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Mean CV Score: 0.76\n",
      "Hyperparameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Mean CV Score: 0.77\n",
      "Hyperparameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Mean CV Score: 0.77\n",
      "Hyperparameters: {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Mean CV Score: 0.77\n",
      "Hyperparameters: {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Mean CV Score: 0.77\n",
      "Hyperparameters: {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Mean CV Score: 0.77\n",
      "Hyperparameters: {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Mean CV Score: 0.78\n",
      "Hyperparameters: {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Mean CV Score: 0.78\n",
      "Hyperparameters: {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Mean CV Score: 0.78\n",
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy: 0.80\n",
      "Precision: 0.81\n",
      "Recall: 0.97\n",
      "F1 Score: 0.88\n",
      "ROC AUC Score: 0.58\n",
      "-------------------------\n",
      "Model: Gradient Boosting\n",
      "Hyperparameters and Cross-Validation Scores:\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "Mean CV Score: 0.80\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "Mean CV Score: 0.80\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "Mean CV Score: 0.80\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 200}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 200}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 100}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 200}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 300}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "Accuracy: 0.80\n",
      "Precision: 0.82\n",
      "Recall: 0.95\n",
      "F1 Score: 0.88\n",
      "ROC AUC Score: 0.62\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LightGBM\n",
      "Hyperparameters and Cross-Validation Scores:\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 200}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 300}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 200}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 100}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 200}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100}\n",
      "Mean CV Score: 0.82\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}\n",
      "Mean CV Score: 0.81\n",
      "Hyperparameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 300}\n",
      "Mean CV Score: 0.81\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Accuracy: 0.81\n",
      "Precision: 0.83\n",
      "Recall: 0.95\n",
      "F1 Score: 0.88\n",
      "ROC AUC Score: 0.63\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter grids for each model\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "        \"penalty\": [\"l1\", \"l2\"]\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"max_depth\": [None, 10, 20, 30],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [None, 10, 20, 30],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [3, 4, 5],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [3, 4, 5],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create lists to store the model names, accuracies, and ROC AUC scores\n",
    "model_names = []\n",
    "accuracies = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Create dictionaries to store the best hyperparameters and best models\n",
    "best_hyperparameters = {}\n",
    "best_models = {}\n",
    "\n",
    "# Loop through each model and perform hyperparameter tuning\n",
    "for name, model in models.items():\n",
    "    # Define the hyperparameter grid for the current model\n",
    "    param_grid = param_grids.get(name, {})  # Get the hyperparameter grid or an empty dictionary\n",
    "    \n",
    "    # Create GridSearchCV object\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc')\n",
    "    \n",
    "    # Fit the model to the data with hyperparameter tuning\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best hyperparameters\n",
    "    best_hyperparameters[name] = grid_search.best_params_\n",
    "    \n",
    "    # Get the best model with tuned hyperparameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Store the best model in the dictionary\n",
    "    best_models[name] = best_model\n",
    "    \n",
    "    # Print the results for each set of hyperparameters\n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Hyperparameters and Cross-Validation Scores:\")\n",
    "    for params, score in zip(grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score']):\n",
    "        print(f\"Hyperparameters: {params}\")\n",
    "        print(f\"Mean CV Score: {score:.2f}\")\n",
    "    \n",
    "    # Evaluate the best model's performance\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Append the results to the lists\n",
    "    model_names.append(name)\n",
    "    accuracies.append(accuracy)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    \n",
    "    # Print the results for the best model\n",
    "    print(f\"Best Hyperparameters: {best_hyperparameters[name]}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(f\"ROC AUC Score: {roc_auc:.2f}\")\n",
    "    print(\"-------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95209aef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Logistic Regression\n",
      "Best Hyperparameters: {'C': 10, 'penalty': 'l2'}\n",
      "Accuracy: 0.78\n",
      "Precision: 0.79\n",
      "Recall: 0.98\n",
      "F1 Score: 0.88\n",
      "ROC AUC Score: 0.54\n",
      "-------------------------\n",
      "Best Model: Decision Tree\n",
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 10}\n",
      "Accuracy: 0.80\n",
      "Precision: 0.81\n",
      "Recall: 0.96\n",
      "F1 Score: 0.88\n",
      "ROC AUC Score: 0.60\n",
      "-------------------------\n",
      "Best Model: Random Forest\n",
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy: 0.80\n",
      "Precision: 0.81\n",
      "Recall: 0.97\n",
      "F1 Score: 0.88\n",
      "ROC AUC Score: 0.58\n",
      "-------------------------\n",
      "Best Model: Gradient Boosting\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "Accuracy: 0.80\n",
      "Precision: 0.82\n",
      "Recall: 0.95\n",
      "F1 Score: 0.88\n",
      "ROC AUC Score: 0.62\n",
      "-------------------------\n",
      "Best Model: LightGBM\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Accuracy: 0.81\n",
      "Precision: 0.83\n",
      "Recall: 0.95\n",
      "F1 Score: 0.88\n",
      "ROC AUC Score: 0.63\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print and visualise the best models\n",
    "for name, best_model in best_models.items():\n",
    "    print(f\"Best Model: {name}\")\n",
    "    print(\"Best Hyperparameters:\", best_hyperparameters[name])\n",
    "    \n",
    "    # Evaluate the best model's performance\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Print the results for the best model\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(f\"ROC AUC Score: {roc_auc:.2f}\")\n",
    "    print(\"-------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cb24e9",
   "metadata": {},
   "source": [
    "## Test on Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2c60458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = df_test.drop('PolicyIssued', axis=1)  # Features\n",
    "y_test = df_test['PolicyIssued']  # Target variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd65bf",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c7dff609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7715900657606003\n",
      "Accuracy: 0.7559533271865959\n",
      "Precision: 0.8281329324012965\n",
      "Recall: 0.8662227850169519\n",
      "F1 Score: 0.8467497204919342\n"
     ]
    }
   ],
   "source": [
    "# Load the trained Logistic Regression model with the best hyperparameters\n",
    "best_lr_model = LogisticRegression(C=10, penalty='l2')\n",
    "\n",
    "# Fit the model to training data\n",
    "best_lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the unseen data\n",
    "lr_predictions = best_lr_model.predict_proba(X_test)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "lr_roc_auc = roc_auc_score(y_test, lr_predictions[:, 1])\n",
    "\n",
    "# Calculate accuracy\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate precision\n",
    "lr_precision = precision_score(y_test, lr_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate recall\n",
    "lr_recall = recall_score(y_test, lr_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate F1 score\n",
    "lr_f1 = f1_score(y_test, lr_predictions.argmax(axis=1))\n",
    "\n",
    "# Print or store the evaluation metrics\n",
    "print(\"ROC AUC:\", lr_roc_auc)\n",
    "print(\"Accuracy:\", lr_accuracy)\n",
    "print(\"Precision:\", lr_precision)\n",
    "print(\"Recall:\", lr_recall)\n",
    "print(\"F1 Score:\", lr_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e024a9d0",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "53b3ac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7848208996624193\n",
      "Accuracy: 0.7743617460973516\n",
      "Precision: 0.8285455095252495\n",
      "Recall: 0.8953882602834852\n",
      "F1 Score: 0.8606710249916565\n"
     ]
    }
   ],
   "source": [
    "# Load the trained Decision Tree model with the best hyperparameters\n",
    "best_dt_model = DecisionTreeClassifier(max_depth=10, min_samples_split=10)\n",
    "\n",
    "# Fit the model to training data\n",
    "best_dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the unseen data\n",
    "dt_predictions = best_dt_model.predict_proba(X_test)\n",
    "\n",
    "# Create a DataFrame with the predictions for further analysis if needed\n",
    "dt_predictions_df = pd.DataFrame({'Probability_Conversion': dt_predictions[:, 1]})\n",
    "\n",
    "# Calculate ROC AUC\n",
    "dt_roc_auc = roc_auc_score(y_test, dt_predictions[:, 1])\n",
    "\n",
    "# Calculate accuracy\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate precision\n",
    "dt_precision = precision_score(y_test, dt_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate recall\n",
    "dt_recall = recall_score(y_test, dt_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate F1 score\n",
    "dt_f1 = f1_score(y_test, dt_predictions.argmax(axis=1))\n",
    "\n",
    "# Print or store the evaluation metrics\n",
    "print(\"ROC AUC:\", dt_roc_auc)\n",
    "print(\"Accuracy:\", dt_accuracy)\n",
    "print(\"Precision:\", dt_precision)\n",
    "print(\"Recall:\", dt_recall)\n",
    "print(\"F1 Score:\", dt_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1bd33a",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e5dfba22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8018000271991934\n",
      "Accuracy: 0.792929132356214\n",
      "Precision: 0.8188981967911402\n",
      "Recall: 0.9423634655447082\n",
      "F1 Score: 0.8763033445387728\n"
     ]
    }
   ],
   "source": [
    "# Load the trained Random Forest model with the best hyperparameters\n",
    "best_rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10)\n",
    "\n",
    "# Fit the model to training data\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the unseen data\n",
    "rf_predictions = best_rf_model.predict_proba(X_test)\n",
    "\n",
    "# Create a DataFrame with the predictions for further analysis if needed\n",
    "rf_predictions_df = pd.DataFrame({'Probability_Conversion': rf_predictions[:, 1]})\n",
    "\n",
    "# Calculate ROC AUC\n",
    "rf_roc_auc = roc_auc_score(y_test, rf_predictions[:, 1])\n",
    "\n",
    "# Calculate accuracy\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate precision\n",
    "rf_precision = precision_score(y_test, rf_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate recall\n",
    "rf_recall = recall_score(y_test, rf_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate F1 score\n",
    "rf_f1 = f1_score(y_test, rf_predictions.argmax(axis=1))\n",
    "\n",
    "# Print or store the evaluation metrics\n",
    "print(\"ROC AUC:\", rf_roc_auc)\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "print(\"Precision:\", rf_precision)\n",
    "print(\"Recall:\", rf_recall)\n",
    "print(\"F1 Score:\", rf_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6690eed1",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "536b9da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7848228799586825\n",
      "Accuracy: 0.7924204368422726\n",
      "Precision: 0.8324937027707808\n",
      "Recall: 0.9180180548180221\n",
      "F1 Score: 0.8731666569535909\n"
     ]
    }
   ],
   "source": [
    "# Load the trained Gradient Boosting Classifier model with the best hyperparameters\n",
    "best_gb_model = GradientBoostingClassifier(n_estimators=300, max_depth=4, learning_rate=0.1)\n",
    "\n",
    "# Fit the model to training data\n",
    "best_gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the unseen data\n",
    "gb_predictions = best_gb_model.predict_proba(X_test)\n",
    "\n",
    "# Create a DataFrame with the predictions for further analysis if needed\n",
    "gb_predictions_df = pd.DataFrame({'Probability_Conversion': gb_predictions[:, 1]})\n",
    "\n",
    "# Calculate ROC AUC\n",
    "gb_roc_auc = roc_auc_score(y_test, gb_predictions[:, 1])\n",
    "\n",
    "# Calculate accuracy\n",
    "gb_accuracy = accuracy_score(y_test, gb_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate precision\n",
    "gb_precision = precision_score(y_test, gb_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate recall\n",
    "gb_recall = recall_score(y_test, gb_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate F1 score\n",
    "gb_f1 = f1_score(y_test, gb_predictions.argmax(axis=1))\n",
    "\n",
    "# Print or store the evaluation metrics\n",
    "print(\"ROC AUC:\", gb_roc_auc)\n",
    "print(\"Accuracy:\", gb_accuracy)\n",
    "print(\"Precision:\", gb_precision)\n",
    "print(\"Recall:\", gb_recall)\n",
    "print(\"F1 Score:\", gb_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ee901c",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4193b12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8245078618113176\n",
      "Accuracy: 0.8078720630782438\n",
      "Precision: 0.8322162162162162\n",
      "Recall: 0.9433438176545076\n",
      "F1 Score: 0.8843024257624782\n"
     ]
    }
   ],
   "source": [
    "# Load the trained LightGBM model with the best hyperparameters\n",
    "best_lightgbm_model = lgb.LGBMClassifier(learning_rate=0.1, max_depth=3, n_estimators=100)\n",
    "\n",
    "# Fit the model to your training data (assuming you have already trained it)\n",
    "best_lightgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the unseen data\n",
    "lgb_predictions = best_lightgbm_model.predict_proba(X_test)\n",
    "\n",
    "# Create a DataFrame with the predictions for further analysis if needed\n",
    "lgb_predictions_df = pd.DataFrame({'Probability_Conversion': lgb_predictions[:, 1]})\n",
    "\n",
    "# Calculate ROC AUC\n",
    "lgb_roc_auc = roc_auc_score(y_test, lgb_predictions[:, 1])\n",
    "\n",
    "# Calculate accuracy\n",
    "lgb_accuracy = accuracy_score(y_test, lgb_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate precision\n",
    "lgb_precision = precision_score(y_test, lgb_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate recall\n",
    "lgb_recall = recall_score(y_test, lgb_predictions.argmax(axis=1))\n",
    "\n",
    "# Calculate F1 score\n",
    "lgb_f1 = f1_score(y_test, lgb_predictions.argmax(axis=1))\n",
    "\n",
    "# Print or store the evaluation metrics\n",
    "print(\"ROC AUC:\", lgb_roc_auc)\n",
    "print(\"Accuracy:\", lgb_accuracy)\n",
    "print(\"Precision:\", lgb_precision)\n",
    "print(\"Recall:\",lgb_recall)\n",
    "print(\"F1 Score:\", lgb_f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
