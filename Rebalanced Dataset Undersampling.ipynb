{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33634b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Ignore ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "283825a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Dataset.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde29996",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d78551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of columns to convert to categorical\n",
    "categorical_columns = df.select_dtypes(include='int64').columns.tolist()\n",
    "\n",
    "# Convert the selected columns to categorical\n",
    "df[categorical_columns] = df[categorical_columns].astype('category')\n",
    "\n",
    "numeric_data = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate MAD for each column\n",
    "mad = numeric_data.mad()\n",
    "\n",
    "# Choose a threshold multiplier\n",
    "k = 3\n",
    "\n",
    "# Calculate the threshold value\n",
    "threshold = k * mad\n",
    "\n",
    "# Identify outliers\n",
    "outliers = (np.abs(numeric_data - numeric_data.median()) > threshold)\n",
    "\n",
    "# Apply logarithm to the specified columns\n",
    "outlier_columns = ['CommissionSacrificePercentage', 'BonusCommissionPercentage']\n",
    "for column in outlier_columns:\n",
    "    df[column] = np.log1p(df[column])\n",
    "    \n",
    "df = df.drop(columns=['PropDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b6a82d",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "921566ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in resampled dataset:\n",
      "0    27888\n",
      "1    27888\n",
      "Name: PolicyIssued, dtype: int64\n",
      "0    24402\n",
      "1    24402\n",
      "Name: PolicyIssued, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = df.drop(\"PolicyIssued\", axis=1)\n",
    "y = df[\"PolicyIssued\"]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Applying RandomUnderSampler to the training data\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled_80, y_resampled_80 = under_sampler.fit_resample(X_train_80, y_train_80)\n",
    "\n",
    "X_resampled_70, y_resampled_70 = under_sampler.fit_resample(X_train_70, y_train_70)\n",
    "\n",
    "# Convert the resampled arrays back to a dataframe\n",
    "resampled_df_80 = pd.DataFrame(X_resampled_80, columns=X_train_80.columns)\n",
    "resampled_df_80[\"PolicyIssued\"] = y_resampled_80\n",
    "\n",
    "resampled_df_70 = pd.DataFrame(X_resampled_70, columns=X_train_70.columns)\n",
    "resampled_df_70[\"PolicyIssued\"] = y_resampled_70\n",
    "\n",
    "# Check the class distribution in the resampled dataset\n",
    "print(\"Class distribution in resampled dataset:\")\n",
    "print(resampled_df_80[\"PolicyIssued\"].value_counts())\n",
    "print(resampled_df_70[\"PolicyIssued\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7c410",
   "metadata": {},
   "source": [
    "# All Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e5fcc",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1203c6f",
   "metadata": {},
   "source": [
    "#### 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7dd083d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix:\n",
      " [[24225  3663]\n",
      " [10523 17365]]\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.77     27888\n",
      "           1       0.83      0.62      0.71     27888\n",
      "\n",
      "    accuracy                           0.75     55776\n",
      "   macro avg       0.76      0.75      0.74     55776\n",
      "weighted avg       0.76      0.75      0.74     55776\n",
      "\n",
      "\n",
      "Training AUC: 0.7456612162937464\n",
      "Training Accuracy: 0.7456612162937464\n",
      "---------------------------------------------\n",
      "Test Confusion Matrix:\n",
      " [[ 6084   888]\n",
      " [ 9255 15226]]\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.87      0.55      6972\n",
      "           1       0.94      0.62      0.75     24481\n",
      "\n",
      "    accuracy                           0.68     31453\n",
      "   macro avg       0.67      0.75      0.65     31453\n",
      "weighted avg       0.82      0.68      0.70     31453\n",
      "\n",
      "\n",
      "Test AUC: 0.747292554182136\n",
      "Test Accuracy: 0.6775188376307506\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise and train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test_80)\n",
    "\n",
    "# Calculate Training AUC and Test AUC\n",
    "train_auc = roc_auc_score(y_train, y_pred_train)\n",
    "test_auc = roc_auc_score(y_test_80, y_pred_test)\n",
    "\n",
    "# Calculate Training Accuracy and Test Accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test_80, y_pred_test)\n",
    "\n",
    "# Evaluate the model\n",
    "confusion_mat_train = confusion_matrix(y_train, y_pred_train)\n",
    "class_report_train = classification_report(y_train, y_pred_train)\n",
    "\n",
    "confusion_mat_test = confusion_matrix(y_test_80, y_pred_test)\n",
    "class_report_test = classification_report(y_test_80, y_pred_test)\n",
    "\n",
    "print(\"Training Confusion Matrix:\\n\", confusion_mat_train)\n",
    "print(\"\\nTraining Classification Report:\\n\", class_report_train)\n",
    "print(\"\\nTraining AUC:\", train_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "print(\"Test Confusion Matrix:\\n\", confusion_mat_test)\n",
    "print(\"\\nTest Classification Report:\\n\", class_report_test)\n",
    "print(\"\\nTest AUC:\", test_auc)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20428c11",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be8b9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7458834867109965\n",
      "Average Accuracy: 0.7459302626264834\n",
      "---------------------------------------------\n",
      "Test AUC: 0.747292554182136\n",
      "Test Accuracy: 0.6775188376307506\n",
      "---------------------------------------------\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.745786560106483\n",
      "Average Accuracy: 0.745876574722039\n",
      "---------------------------------------------\n",
      "Test AUC: 0.747292554182136\n",
      "Test Accuracy: 0.6775188376307506\n",
      "---------------------------------------------\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7456950875026024\n",
      "Average Accuracy: 0.7458226955352887\n",
      "---------------------------------------------\n",
      "Test AUC: 0.747292554182136\n",
      "Test Accuracy: 0.6775188376307506\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# List of k values for k-fold cross-validation\n",
    "num_folds_list = [5, 10, 20]\n",
    "\n",
    "# Initialise logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "    \n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = model.predict(X_test_80)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_test_80, y_pred)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test_80, y_pred)\n",
    "\n",
    "    # Print evaluation metrics for the test data\n",
    "    print(\"Test AUC:\", auc)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39a17d6",
   "metadata": {},
   "source": [
    "#### 70/30 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd3cdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix:\n",
      " [[21291  3111]\n",
      " [ 9339 15063]]\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.77     24402\n",
      "           1       0.83      0.62      0.71     24402\n",
      "\n",
      "    accuracy                           0.74     48804\n",
      "   macro avg       0.76      0.74      0.74     48804\n",
      "weighted avg       0.76      0.74      0.74     48804\n",
      "\n",
      "\n",
      "Training AUC: 0.7448979591836734\n",
      "Training Accuracy: 0.7448979591836735\n",
      "---------------------------------------------\n",
      "Test Confusion Matrix:\n",
      " [[ 9152  1306]\n",
      " [14024 22697]]\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.88      0.54     10458\n",
      "           1       0.95      0.62      0.75     36721\n",
      "\n",
      "    accuracy                           0.68     47179\n",
      "   macro avg       0.67      0.75      0.65     47179\n",
      "weighted avg       0.82      0.68      0.70     47179\n",
      "\n",
      "\n",
      "Test AUC: 0.7466063574526182\n",
      "Test Accuracy: 0.6750672968905658\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise and train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test_70)\n",
    "\n",
    "# Calculate Training AUC and Test AUC\n",
    "train_auc = roc_auc_score(y_train, y_pred_train)\n",
    "test_auc = roc_auc_score(y_test_70, y_pred_test)\n",
    "\n",
    "# Calculate Training Accuracy and Test Accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test_70, y_pred_test)\n",
    "\n",
    "# Evaluate the model\n",
    "confusion_mat_train = confusion_matrix(y_train, y_pred_train)\n",
    "class_report_train = classification_report(y_train, y_pred_train)\n",
    "\n",
    "confusion_mat_test = confusion_matrix(y_test_70, y_pred_test)\n",
    "class_report_test = classification_report(y_test_70, y_pred_test)\n",
    "\n",
    "print(\"Training Confusion Matrix:\\n\", confusion_mat_train)\n",
    "print(\"\\nTraining Classification Report:\\n\", class_report_train)\n",
    "print(\"\\nTraining AUC:\", train_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "print(\"Test Confusion Matrix:\\n\", confusion_mat_test)\n",
    "print(\"\\nTest Classification Report:\\n\", class_report_test)\n",
    "print(\"\\nTest AUC:\", test_auc)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4391cdc7",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b20c3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7458834867109965\n",
      "Average Accuracy: 0.7459302626264834\n",
      "---------------------------------------------\n",
      "Test AUC: 0.7463756986211882\n",
      "Test Accuracy: 0.6767841624451557\n",
      "---------------------------------------------\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.745786560106483\n",
      "Average Accuracy: 0.745876574722039\n",
      "---------------------------------------------\n",
      "Test AUC: 0.7463756986211882\n",
      "Test Accuracy: 0.6767841624451557\n",
      "---------------------------------------------\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7456950875026024\n",
      "Average Accuracy: 0.7458226955352887\n",
      "---------------------------------------------\n",
      "Test AUC: 0.7463756986211882\n",
      "Test Accuracy: 0.6767841624451557\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# List of k values for k-fold cross-validation\n",
    "num_folds_list = [5, 10, 20]\n",
    "\n",
    "# Initialise logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "    \n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = model.predict(X_test_70)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_test_70, y_pred)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test_70, y_pred)\n",
    "\n",
    "    # Print evaluation metrics for the test data\n",
    "    print(\"Test AUC:\", auc)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64598ba2",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a6e885",
   "metadata": {},
   "source": [
    "#### 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35dbd0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.7256167527251864\n",
      "Test AUC: 0.7263481148036567\n",
      "Training Accuracy: 0.7256167527251864\n",
      "Test Accuracy: 0.6342161320064859\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise SGD classifier model\n",
    "model = SGDClassifier(loss='log', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_80)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c438c1e4",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e2d979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.6276471189305945\n",
      "Average Accuracy: 0.624946552369485\n",
      "---------------------------------------------\n",
      "Training AUC: 0.7256167527251864\n",
      "Test AUC: 0.7263481148036567\n",
      "Training Accuracy: 0.7256167527251864\n",
      "Test Accuracy: 0.6342161320064859\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.5988473069290688\n",
      "Average Accuracy: 0.6008542776049741\n",
      "---------------------------------------------\n",
      "Training AUC: 0.7256167527251864\n",
      "Test AUC: 0.7263481148036567\n",
      "Training Accuracy: 0.7256167527251864\n",
      "Test Accuracy: 0.6342161320064859\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.6202035178983514\n",
      "Average Accuracy: 0.6210137772238034\n",
      "---------------------------------------------\n",
      "Training AUC: 0.7256167527251864\n",
      "Test AUC: 0.7263481148036567\n",
      "Training Accuracy: 0.7256167527251864\n",
      "Test Accuracy: 0.6342161320064859\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# List of k values for k-fold cross-validation\n",
    "num_folds_list = [5, 10, 20]\n",
    "\n",
    "# Initialise SGD classifier model\n",
    "model = SGDClassifier(loss='log', random_state=42)\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_80)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7d84ce",
   "metadata": {},
   "source": [
    "#### 70/30 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c103cb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.5173141545774937\n",
      "Test AUC: 0.5172252420263554\n",
      "Training Accuracy: 0.5173141545774936\n",
      "Test Accuracy: 0.7671421607070943\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise SGD classifier model\n",
    "model = SGDClassifier(loss='log', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_70)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8f09d",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "572ec2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7089184576138878\n",
      "Average Accuracy: 0.7082410323955656\n",
      "---------------------------------------------\n",
      "Training AUC: 0.5173141545774937\n",
      "Test AUC: 0.5172252420263554\n",
      "Training Accuracy: 0.5173141545774936\n",
      "Test Accuracy: 0.7671421607070943\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.6554717402814798\n",
      "Average Accuracy: 0.6559528667533191\n",
      "---------------------------------------------\n",
      "Training AUC: 0.5173141545774937\n",
      "Test AUC: 0.5172252420263554\n",
      "Training Accuracy: 0.5173141545774936\n",
      "Test Accuracy: 0.7671421607070943\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.654699152850934\n",
      "Average Accuracy: 0.6566492921471313\n",
      "---------------------------------------------\n",
      "Training AUC: 0.5173141545774937\n",
      "Test AUC: 0.5172252420263554\n",
      "Training Accuracy: 0.5173141545774936\n",
      "Test Accuracy: 0.7671421607070943\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# List of k values for k-fold cross-validation\n",
    "num_folds_list = [5, 10, 20]\n",
    "\n",
    "# Initialise SGD classifier model\n",
    "model = SGDClassifier(loss='log', random_state=42)\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_70)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afead1ed",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0bd17e",
   "metadata": {},
   "source": [
    "#### 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "101c6ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.8793567125645438\n",
      "Test AUC: 0.7078332440793887\n",
      "Training Accuracy: 0.8793567125645438\n",
      "Test Accuracy: 0.6830826948144851\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "\n",
    "# Initialise decision tree classifier model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_80)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f1072",
   "metadata": {},
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1003401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.6964768287083458\n",
      "Average Accuracy: 0.6965362547589228\n",
      "---------------------------------------------\n",
      "Training AUC: 0.8793567125645438\n",
      "Test AUC: 0.7080883126828275\n",
      "Training Accuracy: 0.8793567125645438\n",
      "Test Accuracy: 0.6835595968588052\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.6985053196590707\n",
      "Average Accuracy: 0.6985443466812582\n",
      "---------------------------------------------\n",
      "Training AUC: 0.8793567125645438\n",
      "Test AUC: 0.70782187495247\n",
      "Training Accuracy: 0.8793567125645438\n",
      "Test Accuracy: 0.6834642164499412\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.6986879735957178\n",
      "Average Accuracy: 0.6987593129495717\n",
      "---------------------------------------------\n",
      "Training AUC: 0.8793567125645438\n",
      "Test AUC: 0.7063884919898656\n",
      "Training Accuracy: 0.8793567125645438\n",
      "Test Accuracy: 0.6825104123613009\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise decision tree classifier model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_80)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3241c369",
   "metadata": {},
   "source": [
    "#### 70/30 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55a12b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.8844561921154003\n",
      "Test AUC: 0.6996694263753294\n",
      "Training Accuracy: 0.8844561921154004\n",
      "Test Accuracy: 0.673435214820153\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "\n",
    "# Initialise decision tree classifier model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_70)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73aada2",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "938fd926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7011735211765058\n",
      "Average Accuracy: 0.7011721853108976\n",
      "---------------------------------------------\n",
      "Training AUC: 0.8844561921154003\n",
      "Test AUC: 0.6998137790489135\n",
      "Training Accuracy: 0.8844561921154004\n",
      "Test Accuracy: 0.6731808643676211\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.7006441573612532\n",
      "Average Accuracy: 0.7006394357847927\n",
      "---------------------------------------------\n",
      "Training AUC: 0.8844561921154003\n",
      "Test AUC: 0.6997308528510268\n",
      "Training Accuracy: 0.8844561921154004\n",
      "Test Accuracy: 0.6734776065622416\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7009143267449531\n",
      "Average Accuracy: 0.7009675975984042\n",
      "---------------------------------------------\n",
      "Training AUC: 0.8844561921154003\n",
      "Test AUC: 0.7004721668656131\n",
      "Training Accuracy: 0.8844561921154004\n",
      "Test Accuracy: 0.6748977299222112\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise decision tree classifier model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_70)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025f761",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513afa7",
   "metadata": {},
   "source": [
    "#### 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ccef4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.8793208548479633\n",
      "Test AUC: 0.7193656604863378\n",
      "Training Accuracy: 0.8793208548479633\n",
      "Test Accuracy: 0.707023177439354\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise Random Forest classifier model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_80)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df862c4",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49b9a8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.6968974908712913\n",
      "Average Accuracy: 0.6969665165014829\n",
      "---------------------------------------------\n",
      "Training AUC: 0.8793567125645438\n",
      "Test AUC: 0.7087451207081971\n",
      "Training Accuracy: 0.8793567125645438\n",
      "Test Accuracy: 0.6834642164499412\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.6984788541782001\n",
      "Average Accuracy: 0.6985084433177216\n",
      "---------------------------------------------\n",
      "Training AUC: 0.8793567125645438\n",
      "Test AUC: 0.7081514360909298\n",
      "Training Accuracy: 0.8793567125645438\n",
      "Test Accuracy: 0.6830191078752424\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.6988723939976013\n",
      "Average Accuracy: 0.6989565676903473\n",
      "---------------------------------------------\n",
      "Training AUC: 0.8793567125645438\n",
      "Test AUC: 0.7074038771810415\n",
      "Training Accuracy: 0.8793567125645438\n",
      "Test Accuracy: 0.6825739993005436\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise decision tree classifier model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_80)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3fcb41",
   "metadata": {},
   "source": [
    "#### 70/30 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81b698c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.8844152118678797\n",
      "Test AUC: 0.7081115495007714\n",
      "Training Accuracy: 0.8844152118678796\n",
      "Test Accuracy: 0.6983403632972297\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise Random Forest classifier model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_70)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feea362",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d810706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7003330038543739\n",
      "Average Accuracy: 0.7003320843571188\n",
      "---------------------------------------------\n",
      "Training AUC: 0.8844561921154003\n",
      "Test AUC: 0.6998606675304261\n",
      "Training Accuracy: 0.8844561921154004\n",
      "Test Accuracy: 0.6735199983043303\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.700855899920979\n",
      "Average Accuracy: 0.7008443160330623\n",
      "---------------------------------------------\n",
      "Training AUC: 0.8844561921154003\n",
      "Test AUC: 0.6998733619100874\n",
      "Training Accuracy: 0.8844561921154004\n",
      "Test Accuracy: 0.6738591322410394\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7010076282977952\n",
      "Average Accuracy: 0.7010495732063586\n",
      "---------------------------------------------\n",
      "Training AUC: 0.8844561921154003\n",
      "Test AUC: 0.7001941104754964\n",
      "Training Accuracy: 0.8844561921154004\n",
      "Test Accuracy: 0.674092286822527\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise decision tree classifier model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_70)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f75ad",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa149fa",
   "metadata": {},
   "source": [
    "#### 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2119cf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.7796722604704532\n",
      "Test AUC: 0.7541332386212704\n",
      "Training Accuracy: 0.7796722604704532\n",
      "Test Accuracy: 0.7203446412106953\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise LightGBM classifier model\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_80)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bccb26",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d44b62ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.751098557229944\n",
      "Average Accuracy: 0.7510936896069418\n",
      "---------------------------------------------\n",
      "Training AUC: 0.7796722604704532\n",
      "Test AUC: 0.7541332386212704\n",
      "Training Accuracy: 0.7796722604704532\n",
      "Test Accuracy: 0.7203446412106953\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.7504231258724677\n",
      "Average Accuracy: 0.7504482182461607\n",
      "---------------------------------------------\n",
      "Training AUC: 0.7796722604704532\n",
      "Test AUC: 0.7541332386212704\n",
      "Training Accuracy: 0.7796722604704532\n",
      "Test Accuracy: 0.7203446412106953\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7513976071828362\n",
      "Average Accuracy: 0.7514700545234841\n",
      "---------------------------------------------\n",
      "Training AUC: 0.7796722604704532\n",
      "Test AUC: 0.7541332386212704\n",
      "Training Accuracy: 0.7796722604704532\n",
      "Test Accuracy: 0.7203446412106953\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise LightGBM classifier model\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Initialise LightGBM classifier model\n",
    "        model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_80)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686f1d53",
   "metadata": {},
   "source": [
    "#### 70/30 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce7e0304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.7789730349971314\n",
      "Test AUC: 0.7549012296799502\n",
      "Training Accuracy: 0.7789730349971313\n",
      "Test Accuracy: 0.7248140062315861\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise LightGBM classifier model\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_70)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4571d23",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03642ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7502678757255858\n",
      "Average Accuracy: 0.7502665152052078\n",
      "---------------------------------------------\n",
      "Training AUC: 0.7789730349971314\n",
      "Test AUC: 0.7549012296799502\n",
      "Training Accuracy: 0.7789730349971313\n",
      "Test Accuracy: 0.7248140062315861\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.750799771204703\n",
      "Average Accuracy: 0.7507788060764222\n",
      "---------------------------------------------\n",
      "Training AUC: 0.7789730349971314\n",
      "Test AUC: 0.7549012296799502\n",
      "Training Accuracy: 0.7789730349971313\n",
      "Test Accuracy: 0.7248140062315861\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7506424820595379\n",
      "Average Accuracy: 0.7506967381011547\n",
      "---------------------------------------------\n",
      "Training AUC: 0.7789730349971314\n",
      "Test AUC: 0.7549012296799502\n",
      "Training Accuracy: 0.7789730349971313\n",
      "Test Accuracy: 0.7248140062315861\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise LightGBM classifier model\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Initialise LightGBM classifier model\n",
    "        model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_70)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f9e26d",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a02d5f",
   "metadata": {},
   "source": [
    "#### 8020 Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4309840",
   "metadata": {},
   "source": [
    "Loop over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dab4545",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epochs: 10\n",
      "Epoch 1/10\n",
      "1395/1395 [==============================] - 3s 1ms/step - loss: 0.8250 - accuracy: 0.6883 - val_loss: 0.6056 - val_accuracy: 0.6265\n",
      "Epoch 2/10\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.7180 - accuracy: 0.7212 - val_loss: 1.5435 - val_accuracy: 0.4464\n",
      "Epoch 3/10\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.6701 - accuracy: 0.7290 - val_loss: 0.2532 - val_accuracy: 0.8587\n",
      "Epoch 4/10\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.6479 - accuracy: 0.7323 - val_loss: 0.1131 - val_accuracy: 0.9533\n",
      "Epoch 5/10\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.6439 - accuracy: 0.7350 - val_loss: 1.2478 - val_accuracy: 0.4764\n",
      "Epoch 6/10\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.6452 - accuracy: 0.7347 - val_loss: 1.7963 - val_accuracy: 0.3038\n",
      "Epoch 7/10\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.6123 - accuracy: 0.7410 - val_loss: 0.4848 - val_accuracy: 0.7035\n",
      "Epoch 8/10\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5966 - accuracy: 0.7475 - val_loss: 0.2875 - val_accuracy: 0.8142\n",
      "Epoch 9/10\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.6061 - accuracy: 0.7459 - val_loss: 0.6213 - val_accuracy: 0.6195\n",
      "Epoch 10/10\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5855 - accuracy: 0.7529 - val_loss: 0.6066 - val_accuracy: 0.6250\n",
      "Test Loss: 0.5766180753707886\n",
      "Test Accuracy: 0.6811751127243042\n",
      "=============================================\n",
      " Epochs: 20\n",
      "Epoch 1/20\n",
      "1395/1395 [==============================] - 3s 1ms/step - loss: 0.8443 - accuracy: 0.7085 - val_loss: 0.9411 - val_accuracy: 0.6089\n",
      "Epoch 2/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.6051 - accuracy: 0.7428 - val_loss: 1.0546 - val_accuracy: 0.5750\n",
      "Epoch 3/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.6094 - accuracy: 0.7415 - val_loss: 1.0448 - val_accuracy: 0.5576\n",
      "Epoch 4/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5909 - accuracy: 0.7500 - val_loss: 0.7832 - val_accuracy: 0.6163\n",
      "Epoch 5/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5683 - accuracy: 0.7554 - val_loss: 0.2929 - val_accuracy: 0.8164\n",
      "Epoch 6/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5749 - accuracy: 0.7530 - val_loss: 0.4638 - val_accuracy: 0.6970\n",
      "Epoch 7/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5661 - accuracy: 0.7561 - val_loss: 0.7188 - val_accuracy: 0.6168\n",
      "Epoch 8/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5509 - accuracy: 0.7636 - val_loss: 0.4586 - val_accuracy: 0.6957\n",
      "Epoch 9/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5439 - accuracy: 0.7642 - val_loss: 1.0191 - val_accuracy: 0.5607\n",
      "Epoch 10/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5494 - accuracy: 0.7626 - val_loss: 1.0389 - val_accuracy: 0.5529\n",
      "Epoch 11/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5347 - accuracy: 0.7685 - val_loss: 0.8921 - val_accuracy: 0.6105\n",
      "Epoch 12/20\n",
      "1395/1395 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7673 - val_loss: 0.7368 - val_accuracy: 0.6161\n",
      "Epoch 13/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5329 - accuracy: 0.7705 - val_loss: 0.6879 - val_accuracy: 0.6178\n",
      "Epoch 14/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5319 - accuracy: 0.7689 - val_loss: 0.7003 - val_accuracy: 0.6172\n",
      "Epoch 15/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5270 - accuracy: 0.7731 - val_loss: 0.7187 - val_accuracy: 0.6164\n",
      "Epoch 16/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5251 - accuracy: 0.7744 - val_loss: 0.6744 - val_accuracy: 0.6182\n",
      "Epoch 17/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5253 - accuracy: 0.7748 - val_loss: 0.8051 - val_accuracy: 0.6164\n",
      "Epoch 18/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5238 - accuracy: 0.7746 - val_loss: 0.8272 - val_accuracy: 0.6159\n",
      "Epoch 19/20\n",
      "1395/1395 [==============================] - 2s 2ms/step - loss: 0.5216 - accuracy: 0.7754 - val_loss: 0.7929 - val_accuracy: 0.6158\n",
      "Epoch 20/20\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5202 - accuracy: 0.7769 - val_loss: 0.9158 - val_accuracy: 0.5741\n",
      "Test Loss: 0.7765907645225525\n",
      "Test Accuracy: 0.6449941396713257\n",
      "=============================================\n",
      " Epochs: 30\n",
      "Epoch 1/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.8562 - accuracy: 0.7012 - val_loss: 2.6449 - val_accuracy: 0.1522\n",
      "Epoch 2/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.6526 - accuracy: 0.7250 - val_loss: 2.4988 - val_accuracy: 0.1717\n",
      "Epoch 3/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.6424 - accuracy: 0.7322 - val_loss: 0.3167 - val_accuracy: 0.8100\n",
      "Epoch 4/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.6381 - accuracy: 0.7323 - val_loss: 0.7768 - val_accuracy: 0.6175\n",
      "Epoch 5/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5967 - accuracy: 0.7433 - val_loss: 0.7685 - val_accuracy: 0.6171\n",
      "Epoch 6/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5802 - accuracy: 0.7500 - val_loss: 0.8835 - val_accuracy: 0.6113\n",
      "Epoch 7/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5689 - accuracy: 0.7553 - val_loss: 0.8075 - val_accuracy: 0.6161\n",
      "Epoch 8/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5575 - accuracy: 0.7582 - val_loss: 0.6082 - val_accuracy: 0.6270\n",
      "Epoch 9/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5627 - accuracy: 0.7579 - val_loss: 0.6117 - val_accuracy: 0.6289\n",
      "Epoch 10/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5548 - accuracy: 0.7606 - val_loss: 0.9376 - val_accuracy: 0.6072\n",
      "Epoch 11/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5448 - accuracy: 0.7651 - val_loss: 0.4918 - val_accuracy: 0.6820\n",
      "Epoch 12/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5414 - accuracy: 0.7652 - val_loss: 0.9523 - val_accuracy: 0.5844\n",
      "Epoch 13/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5317 - accuracy: 0.7707 - val_loss: 0.6824 - val_accuracy: 0.6198\n",
      "Epoch 14/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5304 - accuracy: 0.7711 - val_loss: 0.6534 - val_accuracy: 0.6176\n",
      "Epoch 15/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5282 - accuracy: 0.7726 - val_loss: 1.0694 - val_accuracy: 0.5311\n",
      "Epoch 16/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5278 - accuracy: 0.7735 - val_loss: 0.7052 - val_accuracy: 0.6166\n",
      "Epoch 17/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5243 - accuracy: 0.7754 - val_loss: 0.7467 - val_accuracy: 0.6168\n",
      "Epoch 18/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5247 - accuracy: 0.7751 - val_loss: 0.5859 - val_accuracy: 0.6431\n",
      "Epoch 19/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5219 - accuracy: 0.7749 - val_loss: 0.8647 - val_accuracy: 0.6090\n",
      "Epoch 20/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5225 - accuracy: 0.7757 - val_loss: 0.7557 - val_accuracy: 0.6164\n",
      "Epoch 21/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5227 - accuracy: 0.7746 - val_loss: 0.6705 - val_accuracy: 0.6171\n",
      "Epoch 22/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5204 - accuracy: 0.7757 - val_loss: 0.7305 - val_accuracy: 0.6163\n",
      "Epoch 23/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5192 - accuracy: 0.7762 - val_loss: 0.7394 - val_accuracy: 0.6162\n",
      "Epoch 24/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5190 - accuracy: 0.7768 - val_loss: 0.8061 - val_accuracy: 0.6145\n",
      "Epoch 25/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5173 - accuracy: 0.7773 - val_loss: 0.6360 - val_accuracy: 0.6215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5173 - accuracy: 0.7758 - val_loss: 0.8769 - val_accuracy: 0.6057\n",
      "Epoch 27/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5167 - accuracy: 0.7769 - val_loss: 0.8563 - val_accuracy: 0.6076\n",
      "Epoch 28/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5169 - accuracy: 0.7757 - val_loss: 0.7512 - val_accuracy: 0.6165\n",
      "Epoch 29/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5158 - accuracy: 0.7766 - val_loss: 0.7109 - val_accuracy: 0.6179\n",
      "Epoch 30/30\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.5158 - accuracy: 0.7773 - val_loss: 0.7706 - val_accuracy: 0.6143\n",
      "Test Loss: 0.6783196926116943\n",
      "Test Accuracy: 0.6749117970466614\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# List of epochs to iterate over\n",
    "epochs_list = [10, 20, 30] \n",
    "\n",
    "# Create empty lists to store results\n",
    "results = []\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    print(f\" Epochs: {epochs}\")\n",
    "\n",
    "    # Initialise a neural network model\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model on the separate test data\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_80, y_test_80, verbose=0)\n",
    "\n",
    "    # Print metrics for test data\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e06553",
   "metadata": {},
   "source": [
    "#### 70/30 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bb412fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epochs: 10\n",
      "Epoch 1/10\n",
      "1221/1221 [==============================] - 3s 2ms/step - loss: 0.8918 - accuracy: 0.6836 - val_loss: 2.9603 - val_accuracy: 0.1621\n",
      "Epoch 2/10\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.7283 - accuracy: 0.7124 - val_loss: 0.8739 - val_accuracy: 0.6194\n",
      "Epoch 3/10\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.7520 - accuracy: 0.7094 - val_loss: 1.6173 - val_accuracy: 0.4255\n",
      "Epoch 4/10\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.6692 - accuracy: 0.7261 - val_loss: 0.2703 - val_accuracy: 0.8346\n",
      "Epoch 5/10\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.6704 - accuracy: 0.7242 - val_loss: 0.6699 - val_accuracy: 0.6246\n",
      "Epoch 6/10\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.6684 - accuracy: 0.7231 - val_loss: 0.9158 - val_accuracy: 0.6118\n",
      "Epoch 7/10\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.6408 - accuracy: 0.7306 - val_loss: 1.5917 - val_accuracy: 0.3419\n",
      "Epoch 8/10\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.6102 - accuracy: 0.7390 - val_loss: 0.4196 - val_accuracy: 0.7337\n",
      "Epoch 9/10\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5977 - accuracy: 0.7419 - val_loss: 1.0340 - val_accuracy: 0.5739\n",
      "Epoch 10/10\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5811 - accuracy: 0.7452 - val_loss: 0.5349 - val_accuracy: 0.6443\n",
      "Test Loss: 0.5429829359054565\n",
      "Test Accuracy: 0.6856016516685486\n",
      "=============================================\n",
      " Epochs: 20\n",
      "Epoch 1/20\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.8933 - accuracy: 0.6888 - val_loss: 1.6676 - val_accuracy: 0.3131\n",
      "Epoch 2/20\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.6625 - accuracy: 0.7236 - val_loss: 1.0779 - val_accuracy: 0.5457\n",
      "Epoch 3/20\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.6183 - accuracy: 0.7358 - val_loss: 0.2612 - val_accuracy: 0.8576\n",
      "Epoch 4/20\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.6389 - accuracy: 0.7327 - val_loss: 0.1889 - val_accuracy: 0.9131\n",
      "Epoch 5/20\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.6291 - accuracy: 0.7351 - val_loss: 0.4669 - val_accuracy: 0.7032\n",
      "Epoch 6/20\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5930 - accuracy: 0.7435 - val_loss: 1.8975 - val_accuracy: 0.2480\n",
      "Epoch 7/20\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5846 - accuracy: 0.7474 - val_loss: 0.6086 - val_accuracy: 0.6235\n",
      "Epoch 8/20\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5841 - accuracy: 0.7473 - val_loss: 1.1141 - val_accuracy: 0.5140\n",
      "Epoch 9/20\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5772 - accuracy: 0.7487 - val_loss: 0.8119 - val_accuracy: 0.6207\n",
      "Epoch 10/20\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7498 - val_loss: 0.8754 - val_accuracy: 0.6167\n",
      "Epoch 11/20\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5619 - accuracy: 0.7555 - val_loss: 0.6484 - val_accuracy: 0.6245\n",
      "Epoch 12/20\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5630 - accuracy: 0.7536 - val_loss: 0.8821 - val_accuracy: 0.6169\n",
      "Epoch 13/20\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5539 - accuracy: 0.7590 - val_loss: 1.3676 - val_accuracy: 0.3915\n",
      "Epoch 14/20\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5488 - accuracy: 0.7631 - val_loss: 1.2107 - val_accuracy: 0.4385\n",
      "Epoch 15/20\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7660 - val_loss: 0.5712 - val_accuracy: 0.6505\n",
      "Epoch 16/20\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5383 - accuracy: 0.7685 - val_loss: 0.5104 - val_accuracy: 0.6678\n",
      "Epoch 17/20\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5392 - accuracy: 0.7670 - val_loss: 0.7510 - val_accuracy: 0.6208\n",
      "Epoch 18/20\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5321 - accuracy: 0.7703 - val_loss: 0.7690 - val_accuracy: 0.6216\n",
      "Epoch 19/20\n",
      "1221/1221 [==============================] - 2s 2ms/step - loss: 0.5288 - accuracy: 0.7716 - val_loss: 0.4007 - val_accuracy: 0.7613\n",
      "Epoch 20/20\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5303 - accuracy: 0.7713 - val_loss: 0.9300 - val_accuracy: 0.5848\n",
      "Test Loss: 0.7943688631057739\n",
      "Test Accuracy: 0.6491235494613647\n",
      "=============================================\n",
      " Epochs: 30\n",
      "Epoch 1/30\n",
      "1221/1221 [==============================] - 3s 2ms/step - loss: 0.7504 - accuracy: 0.6861 - val_loss: 0.3926 - val_accuracy: 0.7731\n",
      "Epoch 2/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.6954 - accuracy: 0.7165 - val_loss: 2.6433 - val_accuracy: 0.1828\n",
      "Epoch 3/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.6288 - accuracy: 0.7347 - val_loss: 1.1811 - val_accuracy: 0.4955\n",
      "Epoch 4/30\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.6220 - accuracy: 0.7369 - val_loss: 0.3792 - val_accuracy: 0.7645\n",
      "Epoch 5/30\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.6428 - accuracy: 0.7281 - val_loss: 0.3559 - val_accuracy: 0.7852\n",
      "Epoch 6/30\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.6164 - accuracy: 0.7374 - val_loss: 0.6399 - val_accuracy: 0.6336\n",
      "Epoch 7/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.6132 - accuracy: 0.7374 - val_loss: 0.8719 - val_accuracy: 0.6195\n",
      "Epoch 8/30\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5872 - accuracy: 0.7472 - val_loss: 0.8737 - val_accuracy: 0.6185\n",
      "Epoch 9/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5840 - accuracy: 0.7509 - val_loss: 2.3058 - val_accuracy: 0.1147\n",
      "Epoch 10/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5894 - accuracy: 0.7440 - val_loss: 0.6171 - val_accuracy: 0.6281\n",
      "Epoch 11/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5640 - accuracy: 0.7539 - val_loss: 1.0404 - val_accuracy: 0.4978\n",
      "Epoch 12/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5464 - accuracy: 0.7627 - val_loss: 0.8236 - val_accuracy: 0.6199\n",
      "Epoch 13/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5436 - accuracy: 0.7646 - val_loss: 0.9707 - val_accuracy: 0.5851\n",
      "Epoch 14/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5426 - accuracy: 0.7637 - val_loss: 0.6581 - val_accuracy: 0.6229\n",
      "Epoch 15/30\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.7655 - val_loss: 0.9648 - val_accuracy: 0.5833\n",
      "Epoch 16/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5369 - accuracy: 0.7675 - val_loss: 0.7012 - val_accuracy: 0.6240\n",
      "Epoch 17/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5364 - accuracy: 0.7660 - val_loss: 0.8115 - val_accuracy: 0.6194\n",
      "Epoch 18/30\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5332 - accuracy: 0.7676 - val_loss: 1.1881 - val_accuracy: 0.4083\n",
      "Epoch 19/30\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5246 - accuracy: 0.7720 - val_loss: 0.9379 - val_accuracy: 0.5854\n",
      "Epoch 20/30\n",
      "1221/1221 [==============================] - 1s 1ms/step - loss: 0.5276 - accuracy: 0.7697 - val_loss: 1.0759 - val_accuracy: 0.4459\n",
      "Epoch 21/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5241 - accuracy: 0.7726 - val_loss: 0.8773 - val_accuracy: 0.6094\n",
      "Epoch 22/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5243 - accuracy: 0.7735 - val_loss: 0.6776 - val_accuracy: 0.6207\n",
      "Epoch 23/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5221 - accuracy: 0.7732 - val_loss: 0.9618 - val_accuracy: 0.5442\n",
      "Epoch 24/30\n",
      "1221/1221 [==============================] - 2s 2ms/step - loss: 0.5234 - accuracy: 0.7737 - val_loss: 1.0342 - val_accuracy: 0.5863\n",
      "Epoch 25/30\n",
      "1221/1221 [==============================] - 2s 2ms/step - loss: 0.5211 - accuracy: 0.7745 - val_loss: 0.7203 - val_accuracy: 0.6200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "1221/1221 [==============================] - 2s 2ms/step - loss: 0.5202 - accuracy: 0.7749 - val_loss: 0.7873 - val_accuracy: 0.6170\n",
      "Epoch 27/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5204 - accuracy: 0.7754 - val_loss: 0.7845 - val_accuracy: 0.6129\n",
      "Epoch 28/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5192 - accuracy: 0.7747 - val_loss: 0.7228 - val_accuracy: 0.6216\n",
      "Epoch 29/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5201 - accuracy: 0.7744 - val_loss: 0.5510 - val_accuracy: 0.6634\n",
      "Epoch 30/30\n",
      "1221/1221 [==============================] - 2s 1ms/step - loss: 0.5186 - accuracy: 0.7755 - val_loss: 0.8071 - val_accuracy: 0.6140\n",
      "Test Loss: 0.7099330425262451\n",
      "Test Accuracy: 0.670997679233551\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# List of epochs to iterate over\n",
    "epochs_list = [10, 20, 30] \n",
    "\n",
    "# Create empty lists to store results\n",
    "results = []\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    print(f\" Epochs: {epochs}\")\n",
    "\n",
    "    # Initialise a neural network model\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model on the separate test data\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_70, y_test_70, verbose=0)\n",
    "\n",
    "    # Print metrics for test data\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d7e9880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10\n",
      "1743/1743 [==============================] - 1s 753us/step\n",
      "983/983 [==============================] - 1s 668us/step\n",
      "1743/1743 [==============================] - 1s 680us/step\n",
      "Training AUC: 0.7889761222220659\n",
      "Test AUC: 0.7479393816315171\n",
      "Training Accuracy: 0.7464859437751004\n",
      "Test Accuracy: 0.6773280768130227\n",
      "---------------------------------------------\n",
      "Epochs: 20\n",
      "1743/1743 [==============================] - 1s 724us/step\n",
      "983/983 [==============================] - 1s 773us/step\n",
      "1743/1743 [==============================] - 1s 698us/step\n",
      "Training AUC: 0.7901123501155676\n",
      "Test AUC: 0.73708744306326\n",
      "Training Accuracy: 0.736499569707401\n",
      "Test Accuracy: 0.7085810574507996\n",
      "---------------------------------------------\n",
      "Epochs: 30\n",
      "1743/1743 [==============================] - 1s 742us/step\n",
      "983/983 [==============================] - 1s 700us/step\n",
      "1743/1743 [==============================] - 1s 660us/step\n",
      "Training AUC: 0.7877462654177895\n",
      "Test AUC: 0.7393334124748775\n",
      "Training Accuracy: 0.7389020367183018\n",
      "Test Accuracy: 0.6594601468858297\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of epochs to iterate over\n",
    "epochs_list = [10, 20, 30]\n",
    "    \n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Train the model on the entire training data using a neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=len(X.columns)))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Loop over epochs\n",
    "for epochs in epochs_list:\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=0)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred_train = np.round(model.predict(X_train)).astype(int)\n",
    "    y_pred_test = np.round(model.predict(X_test_80)).astype(int)\n",
    "\n",
    "    # Calculate Training AUC and Test AUC\n",
    "    train_auc = roc_auc_score(y_train, model.predict(X_train))\n",
    "    test_auc = roc_auc_score(y_test_80, y_pred_test)\n",
    "\n",
    "    # Calculate Training Accuracy and Test Accuracy\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test_80, y_pred_test)\n",
    "\n",
    "    # Print evaluation metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e983c6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10\n",
      "1526/1526 [==============================] - 1s 674us/step\n",
      "1475/1475 [==============================] - 1s 668us/step\n",
      "1526/1526 [==============================] - 1s 674us/step\n",
      "Training AUC: 0.7296809203229185\n",
      "Test AUC: 0.5594156638249952\n",
      "Training Accuracy: 0.5610195885583149\n",
      "Test Accuracy: 0.7523898344602471\n",
      "---------------------------------------------\n",
      "Epochs: 20\n",
      "1526/1526 [==============================] - 1s 899us/step\n",
      "1475/1475 [==============================] - 1s 807us/step\n",
      "1526/1526 [==============================] - 1s 741us/step\n",
      "Training AUC: 0.7888851361448059\n",
      "Test AUC: 0.680301119174529\n",
      "Training Accuracy: 0.6808458323088271\n",
      "Test Accuracy: 0.760974162233197\n",
      "---------------------------------------------\n",
      "Epochs: 30\n",
      "1526/1526 [==============================] - 1s 687us/step\n",
      "1475/1475 [==============================] - 1s 781us/step\n",
      "1526/1526 [==============================] - 1s 693us/step\n",
      "Training AUC: 0.7968319260895693\n",
      "Test AUC: 0.7472703724599737\n",
      "Training Accuracy: 0.7461478567330546\n",
      "Test Accuracy: 0.6795608215519616\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of epochs to iterate over\n",
    "epochs_list = [10, 20, 30]\n",
    "    \n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Train the model on the entire training data using a neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=len(X.columns)))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Loop over epochs\n",
    "for epochs in epochs_list:\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=0)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred_train = np.round(model.predict(X_train)).astype(int)\n",
    "    y_pred_test = np.round(model.predict(X_test_70)).astype(int)\n",
    "\n",
    "    # Calculate Training AUC and Test AUC\n",
    "    train_auc = roc_auc_score(y_train, model.predict(X_train))\n",
    "    test_auc = roc_auc_score(y_test_70, y_pred_test)\n",
    "\n",
    "    # Calculate Training Accuracy and Test Accuracy\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test_70, y_pred_test)\n",
    "\n",
    "    # Print evaluation metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"---------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
