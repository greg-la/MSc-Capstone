{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33634b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Ignore ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283825a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Dataset.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde29996",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d78551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of columns to convert to categorical\n",
    "categorical_columns = df.select_dtypes(include='int64').columns.tolist()\n",
    "\n",
    "# Convert the selected columns to categorical\n",
    "df[categorical_columns] = df[categorical_columns].astype('category')\n",
    "\n",
    "numeric_data = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate MAD for each column\n",
    "mad = numeric_data.mad()\n",
    "\n",
    "# Choose a threshold multiplier\n",
    "k = 3\n",
    "\n",
    "# Calculate the threshold value\n",
    "threshold = k * mad\n",
    "\n",
    "# Identify outliers\n",
    "outliers = (np.abs(numeric_data - numeric_data.median()) > threshold)\n",
    "\n",
    "# Apply logarithm to the specified columns\n",
    "outlier_columns = ['CommissionSacrificePercentage', 'BonusCommissionPercentage']\n",
    "for column in outlier_columns:\n",
    "    df[column] = np.log1p(df[column])\n",
    "    \n",
    "df = df.drop(columns=['PropDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b6a82d",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "921566ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in resampled dataset:\n",
      "0    97922\n",
      "1    97922\n",
      "Name: PolicyIssued, dtype: int64\n",
      "0    85682\n",
      "1    85682\n",
      "Name: PolicyIssued, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = df.drop(\"PolicyIssued\", axis=1)\n",
    "y = df[\"PolicyIssued\"]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_80 = scaler.fit_transform(X_train_80)\n",
    "X_test_scaled_80 = scaler.transform(X_test_80)\n",
    "\n",
    "X_train_scaled_70 = scaler.fit_transform(X_train_70)\n",
    "X_test_scaled_70 = scaler.transform(X_test_70)\n",
    "\n",
    "# Applying SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled_80, y_resampled_80 = smote.fit_resample(X_train_scaled_80, y_train_80)\n",
    "\n",
    "X_resampled_70, y_resampled_70 = smote.fit_resample(X_train_scaled_70, y_train_70)\n",
    "\n",
    "# Convert the resampled arrays back to a dataframe\n",
    "resampled_df_80 = pd.DataFrame(X_resampled_80, columns=X_train_80.columns)\n",
    "resampled_df_80[\"PolicyIssued\"] = y_resampled_80\n",
    "\n",
    "resampled_df_70 = pd.DataFrame(X_resampled_70, columns=X_train_70.columns)\n",
    "resampled_df_70[\"PolicyIssued\"] = y_resampled_70\n",
    "\n",
    "# Check the class distribution in the resampled dataset\n",
    "print(\"Class distribution in resampled dataset:\")\n",
    "print(resampled_df_80[\"PolicyIssued\"].value_counts())\n",
    "print(resampled_df_70[\"PolicyIssued\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7c410",
   "metadata": {},
   "source": [
    "# All Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e5fcc",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1203c6f",
   "metadata": {},
   "source": [
    "#### 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7dd083d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix:\n",
      " [[84906 13016]\n",
      " [36908 61014]]\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.77     97922\n",
      "           1       0.82      0.62      0.71     97922\n",
      "\n",
      "    accuracy                           0.75    195844\n",
      "   macro avg       0.76      0.75      0.74    195844\n",
      "weighted avg       0.76      0.75      0.74    195844\n",
      "\n",
      "\n",
      "Training AUC: 0.7450828210208124\n",
      "Training Accuracy: 0.7450828210208125\n",
      "---------------------------------------------\n",
      "Test Confusion Matrix:\n",
      " [[ 6088   884]\n",
      " [ 9179 15302]]\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.87      0.55      6972\n",
      "           1       0.95      0.63      0.75     24481\n",
      "\n",
      "    accuracy                           0.68     31453\n",
      "   macro avg       0.67      0.75      0.65     31453\n",
      "weighted avg       0.82      0.68      0.71     31453\n",
      "\n",
      "\n",
      "Test AUC: 0.7491316400886301\n",
      "Test Accuracy: 0.6800623152004578\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise and train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test_scaled_80)\n",
    "\n",
    "# Calculate Training AUC and Test AUC\n",
    "train_auc = roc_auc_score(y_train, y_pred_train)\n",
    "test_auc = roc_auc_score(y_test_80, y_pred_test)\n",
    "\n",
    "# Calculate Training Accuracy and Test Accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test_80, y_pred_test)\n",
    "\n",
    "# Evaluate the model\n",
    "confusion_mat_train = confusion_matrix(y_train, y_pred_train)\n",
    "class_report_train = classification_report(y_train, y_pred_train)\n",
    "\n",
    "confusion_mat_test = confusion_matrix(y_test_80, y_pred_test)\n",
    "class_report_test = classification_report(y_test_80, y_pred_test)\n",
    "\n",
    "print(\"Training Confusion Matrix:\\n\", confusion_mat_train)\n",
    "print(\"\\nTraining Classification Report:\\n\", class_report_train)\n",
    "print(\"\\nTraining AUC:\", train_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "print(\"Test Confusion Matrix:\\n\", confusion_mat_test)\n",
    "print(\"\\nTest Classification Report:\\n\", class_report_test)\n",
    "print(\"\\nTest AUC:\", test_auc)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20428c11",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be8b9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7451126129884722\n",
      "Average Accuracy: 0.7450981408992405\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.7491316400886301\n",
      "Test Accuracy: 0.6800623152004578\n",
      "---------------------------------------------\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.7452153304382247\n",
      "Average Accuracy: 0.7452053720709627\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.7491316400886301\n",
      "Test Accuracy: 0.6800623152004578\n",
      "---------------------------------------------\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7451369120351143\n",
      "Average Accuracy: 0.7451288328948448\n",
      "---------------------------------------------\n",
      "Test AUC: 0.7491316400886301\n",
      "Test Accuracy: 0.6800623152004578\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# List of k values for k-fold cross-validation\n",
    "num_folds_list = [5, 10, 20]\n",
    "\n",
    "# Initialise logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "    \n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = model.predict(X_test_scaled_80)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_test_80, y_pred)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test_80, y_pred)\n",
    "\n",
    "    # Print evaluation metrics for the test data\n",
    "    print(\"Test AUC:\", auc)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39a17d6",
   "metadata": {},
   "source": [
    "#### 70/30 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cd3cdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix:\n",
      " [[74548 11134]\n",
      " [32413 53269]]\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.77     85682\n",
      "           1       0.83      0.62      0.71     85682\n",
      "\n",
      "    accuracy                           0.75    171364\n",
      "   macro avg       0.76      0.75      0.74    171364\n",
      "weighted avg       0.76      0.75      0.74    171364\n",
      "\n",
      "\n",
      "Training AUC: 0.7458801148432577\n",
      "Training Accuracy: 0.7458801148432577\n",
      "---------------------------------------------\n",
      "Test Confusion Matrix:\n",
      " [[ 9114  1344]\n",
      " [13859 22862]]\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.87      0.55     10458\n",
      "           1       0.94      0.62      0.75     36721\n",
      "\n",
      "    accuracy                           0.68     47179\n",
      "   macro avg       0.67      0.75      0.65     47179\n",
      "weighted avg       0.82      0.68      0.70     47179\n",
      "\n",
      "\n",
      "Test AUC: 0.747036237321498\n",
      "Test Accuracy: 0.6777591725131944\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise and train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test_scaled_70)\n",
    "\n",
    "# Calculate Training AUC and Test AUC\n",
    "train_auc = roc_auc_score(y_train, y_pred_train)\n",
    "test_auc = roc_auc_score(y_test_70, y_pred_test)\n",
    "\n",
    "# Calculate Training Accuracy and Test Accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test_70, y_pred_test)\n",
    "\n",
    "# Evaluate the model\n",
    "confusion_mat_train = confusion_matrix(y_train, y_pred_train)\n",
    "class_report_train = classification_report(y_train, y_pred_train)\n",
    "\n",
    "confusion_mat_test = confusion_matrix(y_test_70, y_pred_test)\n",
    "class_report_test = classification_report(y_test_70, y_pred_test)\n",
    "\n",
    "print(\"Training Confusion Matrix:\\n\", confusion_mat_train)\n",
    "print(\"\\nTraining Classification Report:\\n\", class_report_train)\n",
    "print(\"\\nTraining AUC:\", train_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "print(\"Test Confusion Matrix:\\n\", confusion_mat_test)\n",
    "print(\"\\nTest Classification Report:\\n\", class_report_test)\n",
    "print(\"\\nTest AUC:\", test_auc)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4391cdc7",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b20c3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7451126129884722\n",
      "Average Accuracy: 0.7450981408992405\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.7479896776751963\n",
      "Test Accuracy: 0.6791369041310753\n",
      "---------------------------------------------\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.7452153304382247\n",
      "Average Accuracy: 0.7452053720709627\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.7479896776751963\n",
      "Test Accuracy: 0.6791369041310753\n",
      "---------------------------------------------\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7451369120351143\n",
      "Average Accuracy: 0.7451288328948448\n",
      "---------------------------------------------\n",
      "Test AUC: 0.7479896776751963\n",
      "Test Accuracy: 0.6791369041310753\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# List of k values for k-fold cross-validation\n",
    "num_folds_list = [5, 10, 20]\n",
    "\n",
    "# Initialise logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "    \n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = model.predict(X_test_scaled_70)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_test_70, y_pred)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test_70, y_pred)\n",
    "\n",
    "    # Print evaluation metrics for the test data\n",
    "    print(\"Test AUC:\", auc)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcc6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64598ba2",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a6e885",
   "metadata": {},
   "source": [
    "#### 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35dbd0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.7441381916219032\n",
      "Test AUC: 0.7481123499641426\n",
      "Training Accuracy: 0.7441381916219032\n",
      "Test Accuracy: 0.6848631291132802\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise SGD classifier model\n",
    "model = SGDClassifier(loss='log', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_scaled_80)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c438c1e4",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e2d979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7438552938226421\n",
      "Average Accuracy: 0.7438165139504831\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.7441381916219032\n",
      "Test AUC: 0.7481123499641426\n",
      "Training Accuracy: 0.7441381916219032\n",
      "Test Accuracy: 0.6848631291132802\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.7430257612809805\n",
      "Average Accuracy: 0.7430097096972139\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.7441381916219032\n",
      "Test AUC: 0.7481123499641426\n",
      "Training Accuracy: 0.7441381916219032\n",
      "Test Accuracy: 0.6848631291132802\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7436270408590044\n",
      "Average Accuracy: 0.7436378667502263\n",
      "---------------------------------------------\n",
      "Training AUC: 0.7441381916219032\n",
      "Test AUC: 0.7481123499641426\n",
      "Training Accuracy: 0.7441381916219032\n",
      "Test Accuracy: 0.6848631291132802\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# List of k values for k-fold cross-validation\n",
    "num_folds_list = [5, 10, 20]\n",
    "\n",
    "# Initialise SGD classifier model\n",
    "model = SGDClassifier(loss='log', random_state=42)\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_scaled_80)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7d84ce",
   "metadata": {},
   "source": [
    "#### 70/30 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c103cb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.7430440465908825\n",
      "Test AUC: 0.744983151212081\n",
      "Training Accuracy: 0.7430440465908825\n",
      "Test Accuracy: 0.6829733567900973\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise SGD classifier model\n",
    "model = SGDClassifier(loss='log', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_scaled_70)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8f09d",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "572ec2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7446670782625764\n",
      "Average Accuracy: 0.7446780083861709\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.7430440465908825\n",
      "Test AUC: 0.744983151212081\n",
      "Training Accuracy: 0.7430440465908825\n",
      "Test Accuracy: 0.6829733567900973\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.7442356886883358\n",
      "Average Accuracy: 0.7442228423142612\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.7430440465908825\n",
      "Test AUC: 0.744983151212081\n",
      "Training Accuracy: 0.7430440465908825\n",
      "Test Accuracy: 0.6829733567900973\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7447565050471809\n",
      "Average Accuracy: 0.7447713889305675\n",
      "---------------------------------------------\n",
      "Training AUC: 0.7430440465908825\n",
      "Test AUC: 0.744983151212081\n",
      "Training Accuracy: 0.7430440465908825\n",
      "Test Accuracy: 0.6829733567900973\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# List of k values for k-fold cross-validation\n",
    "num_folds_list = [5, 10, 20]\n",
    "\n",
    "# Initialise SGD classifier model\n",
    "model = SGDClassifier(loss='log', random_state=42)\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_scaled_70)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afead1ed",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0bd17e",
   "metadata": {},
   "source": [
    "#### 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "101c6ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.8993076121811238\n",
      "Test AUC: 0.6989925512269247\n",
      "Training Accuracy: 0.8993076121811238\n",
      "Test Accuracy: 0.7387848535910724\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "\n",
    "# Initialise decision tree classifier model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_scaled_80)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f1072",
   "metadata": {},
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1003401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7752625774716503\n",
      "Average Accuracy: 0.7752445875356279\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.8993076121811238\n",
      "Test AUC: 0.6990552117847173\n",
      "Training Accuracy: 0.8993076121811238\n",
      "Test Accuracy: 0.7384033319556164\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.7783052570194336\n",
      "Average Accuracy: 0.7782929188024882\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.8993076121811238\n",
      "Test AUC: 0.6994945592590532\n",
      "Training Accuracy: 0.8993076121811238\n",
      "Test Accuracy: 0.7390074078784218\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7793871042141495\n",
      "Average Accuracy: 0.7793804934113268\n",
      "---------------------------------------------\n",
      "Training AUC: 0.8993076121811238\n",
      "Test AUC: 0.6991359820932471\n",
      "Training Accuracy: 0.8993076121811238\n",
      "Test Accuracy: 0.7388484405303151\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise decision tree classifier model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_scaled_80)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3241c369",
   "metadata": {},
   "source": [
    "#### 70/30 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a12b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.9038771270511893\n",
      "Test AUC: 0.6950532460612049\n",
      "Training Accuracy: 0.9038771270511893\n",
      "Test Accuracy: 0.7347548697513724\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "\n",
    "# Initialise decision tree classifier model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_scaled_70)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73aada2",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "938fd926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7770326311011321\n",
      "Average Accuracy: 0.7770360057336623\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.9038771270511893\n",
      "Test AUC: 0.694377554828536\n",
      "Training Accuracy: 0.9038771270511893\n",
      "Test Accuracy: 0.7342885605883974\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.7797616755554133\n",
      "Average Accuracy: 0.7797612090585199\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.9038771270511893\n",
      "Test AUC: 0.6946979961248576\n",
      "Training Accuracy: 0.9038771270511893\n",
      "Test Accuracy: 0.7346276945251065\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7808064543141777\n",
      "Average Accuracy: 0.7808116132631916\n",
      "---------------------------------------------\n",
      "Training AUC: 0.9038771270511893\n",
      "Test AUC: 0.6942946286306492\n",
      "Training Accuracy: 0.9038771270511893\n",
      "Test Accuracy: 0.7345853027830178\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise decision tree classifier model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_scaled_70)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025f761",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513afa7",
   "metadata": {},
   "source": [
    "#### 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ccef4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.8992412328179572\n",
      "Test AUC: 0.7020476181336361\n",
      "Training Accuracy: 0.8992412328179572\n",
      "Test Accuracy: 0.7500079483674054\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise Random Forest classifier model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_scaled_80)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df862c4",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49b9a8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7750824328926993\n",
      "Average Accuracy: 0.7750658752995441\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.8993076121811238\n",
      "Test AUC: 0.6996883558556295\n",
      "Training Accuracy: 0.8993076121811238\n",
      "Test Accuracy: 0.7393889295138778\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.7780557964971635\n",
      "Average Accuracy: 0.7780427226364548\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.8993076121811238\n",
      "Test AUC: 0.6991065032155911\n",
      "Training Accuracy: 0.8993076121811238\n",
      "Test Accuracy: 0.7384033319556164\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7791310543902574\n",
      "Average Accuracy: 0.7791251970319937\n",
      "---------------------------------------------\n",
      "Training AUC: 0.8993076121811238\n",
      "Test AUC: 0.6992186038030173\n",
      "Training Accuracy: 0.8993076121811238\n",
      "Test Accuracy: 0.738657679712587\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise decision tree classifier model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_scaled_80)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3fcb41",
   "metadata": {},
   "source": [
    "#### 70/30 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81b698c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.9038187717373544\n",
      "Test AUC: 0.6955478177908271\n",
      "Training Accuracy: 0.9038187717373544\n",
      "Test Accuracy: 0.7457979185654634\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise Random Forest classifier model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_scaled_70)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feea362",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d810706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7775006933129462\n",
      "Average Accuracy: 0.7775028480741346\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.9038771270511893\n",
      "Test AUC: 0.6941935826705317\n",
      "Training Accuracy: 0.9038771270511893\n",
      "Test Accuracy: 0.7340554060069099\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.7798253614534119\n",
      "Average Accuracy: 0.7798254020831845\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.9038771270511893\n",
      "Test AUC: 0.6943227828117567\n",
      "Training Accuracy: 0.9038771270511893\n",
      "Test Accuracy: 0.7343097564594417\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7810927090968591\n",
      "Average Accuracy: 0.7810975514413181\n",
      "---------------------------------------------\n",
      "Training AUC: 0.9038771270511893\n",
      "Test AUC: 0.6942059697811059\n",
      "Training Accuracy: 0.9038771270511893\n",
      "Test Accuracy: 0.7345005192988406\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise decision tree classifier model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_scaled_70)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f75ad",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa149fa",
   "metadata": {},
   "source": [
    "#### 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2119cf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.7676109556585854\n",
      "Test AUC: 0.7505888627716325\n",
      "Training Accuracy: 0.7676109556585854\n",
      "Test Accuracy: 0.7010142116809207\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise LightGBM classifier model\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_scaled_80)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bccb26",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d44b62ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7648755892156187\n",
      "Average Accuracy: 0.7648587599266092\n",
      "---------------------------------------------\n",
      "Training AUC: 0.7676109556585854\n",
      "Test AUC: 0.7505888627716325\n",
      "Training Accuracy: 0.7676109556585854\n",
      "Test Accuracy: 0.7010142116809207\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.7655487824404748\n",
      "Average Accuracy: 0.7655429778817322\n",
      "---------------------------------------------\n",
      "Training AUC: 0.7676109556585854\n",
      "Test AUC: 0.7505888627716325\n",
      "Training Accuracy: 0.7676109556585854\n",
      "Test Accuracy: 0.7010142116809207\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7649567222737803\n",
      "Average Accuracy: 0.7649404973598922\n",
      "---------------------------------------------\n",
      "Training AUC: 0.7676109556585854\n",
      "Test AUC: 0.7505888627716325\n",
      "Training Accuracy: 0.7676109556585854\n",
      "Test Accuracy: 0.7010142116809207\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise LightGBM classifier model\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Initialise LightGBM classifier model\n",
    "        model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_scaled_80)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_80, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_80, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686f1d53",
   "metadata": {},
   "source": [
    "#### 70/30 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce7e0304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.769549030134684\n",
      "Test AUC: 0.7512973656013996\n",
      "Training Accuracy: 0.769549030134684\n",
      "Test Accuracy: 0.7011594141461244\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise LightGBM classifier model\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_scaled_70)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate AUC and accuracy for test and training data\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "# Print metrics for training and test data\n",
    "print(\"Training AUC:\", train_auc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4571d23",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03642ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Average AUC: 0.7673676751085572\n",
      "Average Accuracy: 0.7673607174466086\n",
      "---------------------------------------------\n",
      "Training AUC: 0.769549030134684\n",
      "Test AUC: 0.7512973656013996\n",
      "Training Accuracy: 0.769549030134684\n",
      "Test Accuracy: 0.7011594141461244\n",
      "=============================================\n",
      "Number of Folds: 10\n",
      "Average AUC: 0.767218307971391\n",
      "Average Accuracy: 0.7672148366650544\n",
      "---------------------------------------------\n",
      "Training AUC: 0.769549030134684\n",
      "Test AUC: 0.7512973656013996\n",
      "Training Accuracy: 0.769549030134684\n",
      "Test Accuracy: 0.7011594141461244\n",
      "=============================================\n",
      "Number of Folds: 20\n",
      "Average AUC: 0.7674007826989743\n",
      "Average Accuracy: 0.7674132602821345\n",
      "---------------------------------------------\n",
      "Training AUC: 0.769549030134684\n",
      "Test AUC: 0.7512973656013996\n",
      "Training Accuracy: 0.769549030134684\n",
      "Test Accuracy: 0.7011594141461244\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Initialise LightGBM classifier model\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for num_folds in num_folds_list:\n",
    "    print(f\"Number of Folds: {num_folds}\")\n",
    "\n",
    "    # Initialise k-fold cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    fold_auc_scores = []\n",
    "    fold_accuracy_scores = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_fold_val, y_fold_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Initialise LightGBM classifier model\n",
    "        model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "        # Train the model on the fold training data\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict on the fold validation data\n",
    "        y_fold_val_pred = model.predict(X_fold_val)\n",
    "\n",
    "        # Calculate AUC and accuracy for the fold\n",
    "        fold_auc = roc_auc_score(y_fold_val, y_fold_val_pred)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_val_pred)\n",
    "\n",
    "        fold_auc_scores.append(fold_auc)\n",
    "        fold_accuracy_scores.append(fold_accuracy)\n",
    "\n",
    "    # Calculate average AUC and accuracy for the current number of folds\n",
    "    avg_auc = sum(fold_auc_scores) / num_folds\n",
    "    avg_accuracy = sum(fold_accuracy_scores) / num_folds\n",
    "\n",
    "    # Print average metrics for cross-validation\n",
    "    print(\"Average AUC:\", avg_auc)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    # Train the model on the entire training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = model.predict(X_test_scaled_70)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate AUC and accuracy for test and training data\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    test_auc = roc_auc_score(y_test_70, y_test_pred)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_70, y_test_pred)\n",
    "\n",
    "    # Print metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f9e26d",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a02d5f",
   "metadata": {},
   "source": [
    "#### 8020 Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4309840",
   "metadata": {},
   "source": [
    "Loop over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dab4545",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epochs: 10\n",
      "Epoch 1/10\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5184 - accuracy: 0.7280 - val_loss: 0.6957 - val_accuracy: 0.7407\n",
      "Epoch 2/10\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5124 - accuracy: 0.7329 - val_loss: 0.7095 - val_accuracy: 0.7148\n",
      "Epoch 3/10\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5110 - accuracy: 0.7352 - val_loss: 0.7522 - val_accuracy: 0.6723\n",
      "Epoch 4/10\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5098 - accuracy: 0.7362 - val_loss: 0.7344 - val_accuracy: 0.7036\n",
      "Epoch 5/10\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5091 - accuracy: 0.7361 - val_loss: 0.7233 - val_accuracy: 0.7088\n",
      "Epoch 6/10\n",
      "4897/4897 [==============================] - 8s 2ms/step - loss: 0.5083 - accuracy: 0.7365 - val_loss: 0.7619 - val_accuracy: 0.6642\n",
      "Epoch 7/10\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5077 - accuracy: 0.7372 - val_loss: 0.7002 - val_accuracy: 0.7226\n",
      "Epoch 8/10\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5069 - accuracy: 0.7375 - val_loss: 0.7329 - val_accuracy: 0.6968\n",
      "Epoch 9/10\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5063 - accuracy: 0.7378 - val_loss: 0.6856 - val_accuracy: 0.7246\n",
      "Epoch 10/10\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5059 - accuracy: 0.7381 - val_loss: 0.7213 - val_accuracy: 0.6962\n",
      "Test Loss: 0.45850953459739685\n",
      "Test Accuracy: 0.7465106844902039\n",
      "=============================================\n",
      " Epochs: 20\n",
      "Epoch 1/20\n",
      "4897/4897 [==============================] - 8s 1ms/step - loss: 0.5178 - accuracy: 0.7297 - val_loss: 0.7324 - val_accuracy: 0.7103\n",
      "Epoch 2/20\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5125 - accuracy: 0.7342 - val_loss: 0.7539 - val_accuracy: 0.6832\n",
      "Epoch 3/20\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5109 - accuracy: 0.7350 - val_loss: 0.6996 - val_accuracy: 0.7492\n",
      "Epoch 4/20\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5101 - accuracy: 0.7362 - val_loss: 0.7202 - val_accuracy: 0.7049\n",
      "Epoch 5/20\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5092 - accuracy: 0.7364 - val_loss: 0.7463 - val_accuracy: 0.6798\n",
      "Epoch 6/20\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5085 - accuracy: 0.7369 - val_loss: 0.7234 - val_accuracy: 0.6912\n",
      "Epoch 7/20\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5076 - accuracy: 0.7377 - val_loss: 0.7293 - val_accuracy: 0.7020\n",
      "Epoch 8/20\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5071 - accuracy: 0.7384 - val_loss: 0.7551 - val_accuracy: 0.6826\n",
      "Epoch 9/20\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5066 - accuracy: 0.7380 - val_loss: 0.6928 - val_accuracy: 0.7274\n",
      "Epoch 10/20\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5058 - accuracy: 0.7389 - val_loss: 0.7209 - val_accuracy: 0.6923\n",
      "Epoch 11/20\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5055 - accuracy: 0.7389 - val_loss: 0.6952 - val_accuracy: 0.7378\n",
      "Epoch 12/20\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5052 - accuracy: 0.7386 - val_loss: 0.7453 - val_accuracy: 0.6663\n",
      "Epoch 13/20\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5046 - accuracy: 0.7395 - val_loss: 0.6911 - val_accuracy: 0.7154\n",
      "Epoch 14/20\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5041 - accuracy: 0.7405 - val_loss: 0.6889 - val_accuracy: 0.7068\n",
      "Epoch 15/20\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5037 - accuracy: 0.7389 - val_loss: 0.7250 - val_accuracy: 0.7085\n",
      "Epoch 16/20\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5033 - accuracy: 0.7402 - val_loss: 0.7454 - val_accuracy: 0.6647\n",
      "Epoch 17/20\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5029 - accuracy: 0.7401 - val_loss: 0.7509 - val_accuracy: 0.6760\n",
      "Epoch 18/20\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5027 - accuracy: 0.7401 - val_loss: 0.6841 - val_accuracy: 0.7385\n",
      "Epoch 19/20\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5025 - accuracy: 0.7410 - val_loss: 0.6815 - val_accuracy: 0.7246\n",
      "Epoch 20/20\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5020 - accuracy: 0.7419 - val_loss: 0.7478 - val_accuracy: 0.6598\n",
      "Test Loss: 0.4497790038585663\n",
      "Test Accuracy: 0.7566846013069153\n",
      "=============================================\n",
      " Epochs: 30\n",
      "Epoch 1/30\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5174 - accuracy: 0.7296 - val_loss: 0.7255 - val_accuracy: 0.7291\n",
      "Epoch 2/30\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5123 - accuracy: 0.7348 - val_loss: 0.7045 - val_accuracy: 0.7348\n",
      "Epoch 3/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5109 - accuracy: 0.7357 - val_loss: 0.7505 - val_accuracy: 0.6734\n",
      "Epoch 4/30\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5098 - accuracy: 0.7366 - val_loss: 0.7110 - val_accuracy: 0.7232\n",
      "Epoch 5/30\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5091 - accuracy: 0.7376 - val_loss: 0.7126 - val_accuracy: 0.7061\n",
      "Epoch 6/30\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5085 - accuracy: 0.7373 - val_loss: 0.7006 - val_accuracy: 0.7070\n",
      "Epoch 7/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5079 - accuracy: 0.7375 - val_loss: 0.7096 - val_accuracy: 0.7163\n",
      "Epoch 8/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5073 - accuracy: 0.7383 - val_loss: 0.7097 - val_accuracy: 0.7107\n",
      "Epoch 9/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5071 - accuracy: 0.7385 - val_loss: 0.6770 - val_accuracy: 0.7362\n",
      "Epoch 10/30\n",
      "4897/4897 [==============================] - 8s 2ms/step - loss: 0.5064 - accuracy: 0.7383 - val_loss: 0.7180 - val_accuracy: 0.7234\n",
      "Epoch 11/30\n",
      "4897/4897 [==============================] - 8s 2ms/step - loss: 0.5058 - accuracy: 0.7393 - val_loss: 0.7287 - val_accuracy: 0.6891\n",
      "Epoch 12/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5056 - accuracy: 0.7396 - val_loss: 0.7407 - val_accuracy: 0.6937\n",
      "Epoch 13/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5051 - accuracy: 0.7392 - val_loss: 0.7185 - val_accuracy: 0.7199\n",
      "Epoch 14/30\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5047 - accuracy: 0.7402 - val_loss: 0.6892 - val_accuracy: 0.7080\n",
      "Epoch 15/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5042 - accuracy: 0.7406 - val_loss: 0.7192 - val_accuracy: 0.7042\n",
      "Epoch 16/30\n",
      "4897/4897 [==============================] - 8s 2ms/step - loss: 0.5039 - accuracy: 0.7403 - val_loss: 0.7034 - val_accuracy: 0.6933\n",
      "Epoch 17/30\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5036 - accuracy: 0.7408 - val_loss: 0.7070 - val_accuracy: 0.7072\n",
      "Epoch 18/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5032 - accuracy: 0.7403 - val_loss: 0.7173 - val_accuracy: 0.7176\n",
      "Epoch 19/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5027 - accuracy: 0.7414 - val_loss: 0.6946 - val_accuracy: 0.7456\n",
      "Epoch 20/30\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5026 - accuracy: 0.7402 - val_loss: 0.6777 - val_accuracy: 0.7286\n",
      "Epoch 21/30\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5020 - accuracy: 0.7414 - val_loss: 0.7413 - val_accuracy: 0.6934\n",
      "Epoch 22/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5017 - accuracy: 0.7421 - val_loss: 0.7030 - val_accuracy: 0.6958\n",
      "Epoch 23/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5013 - accuracy: 0.7425 - val_loss: 0.6841 - val_accuracy: 0.7209\n",
      "Epoch 24/30\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5013 - accuracy: 0.7420 - val_loss: 0.7303 - val_accuracy: 0.7025\n",
      "Epoch 25/30\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5008 - accuracy: 0.7420 - val_loss: 0.6932 - val_accuracy: 0.7053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "4897/4897 [==============================] - 7s 1ms/step - loss: 0.5006 - accuracy: 0.7423 - val_loss: 0.7380 - val_accuracy: 0.6883\n",
      "Epoch 27/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5003 - accuracy: 0.7426 - val_loss: 0.7200 - val_accuracy: 0.6814\n",
      "Epoch 28/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.5003 - accuracy: 0.7425 - val_loss: 0.7140 - val_accuracy: 0.6930\n",
      "Epoch 29/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.4997 - accuracy: 0.7432 - val_loss: 0.6848 - val_accuracy: 0.7125\n",
      "Epoch 30/30\n",
      "4897/4897 [==============================] - 6s 1ms/step - loss: 0.4993 - accuracy: 0.7431 - val_loss: 0.7556 - val_accuracy: 0.6410\n",
      "Test Loss: 0.44886070489883423\n",
      "Test Accuracy: 0.7592916488647461\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# List of epochs to iterate over\n",
    "epochs_list = [10, 20, 30] \n",
    "\n",
    "# Create empty lists to store results\n",
    "results = []\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    print(f\" Epochs: {epochs}\")\n",
    "\n",
    "    # Initialise a neural network model\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model on the separate test data\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_scaled_80, y_test_80, verbose=0)\n",
    "\n",
    "    # Print metrics for test data\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e06553",
   "metadata": {},
   "source": [
    "#### 70/30 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bb412fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epochs: 10\n",
      "Epoch 1/10\n",
      "4285/4285 [==============================] - 7s 1ms/step - loss: 0.5171 - accuracy: 0.7302 - val_loss: 0.8075 - val_accuracy: 0.6136\n",
      "Epoch 2/10\n",
      "4285/4285 [==============================] - 5s 1ms/step - loss: 0.5116 - accuracy: 0.7340 - val_loss: 0.7042 - val_accuracy: 0.7247\n",
      "Epoch 3/10\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5099 - accuracy: 0.7360 - val_loss: 0.6825 - val_accuracy: 0.7209\n",
      "Epoch 4/10\n",
      "4285/4285 [==============================] - 7s 2ms/step - loss: 0.5091 - accuracy: 0.7356 - val_loss: 0.6819 - val_accuracy: 0.7378\n",
      "Epoch 5/10\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5081 - accuracy: 0.7367 - val_loss: 0.7000 - val_accuracy: 0.7132\n",
      "Epoch 6/10\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5071 - accuracy: 0.7378 - val_loss: 0.6768 - val_accuracy: 0.7512\n",
      "Epoch 7/10\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5063 - accuracy: 0.7368 - val_loss: 0.7152 - val_accuracy: 0.6979\n",
      "Epoch 8/10\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5058 - accuracy: 0.7383 - val_loss: 0.7266 - val_accuracy: 0.6814\n",
      "Epoch 9/10\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5051 - accuracy: 0.7382 - val_loss: 0.6774 - val_accuracy: 0.7274\n",
      "Epoch 10/10\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5044 - accuracy: 0.7391 - val_loss: 0.7105 - val_accuracy: 0.6994\n",
      "Test Loss: 0.45754432678222656\n",
      "Test Accuracy: 0.7475147843360901\n",
      "=============================================\n",
      " Epochs: 20\n",
      "Epoch 1/20\n",
      "4285/4285 [==============================] - 8s 2ms/step - loss: 0.5184 - accuracy: 0.7300 - val_loss: 0.6870 - val_accuracy: 0.7577\n",
      "Epoch 2/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5124 - accuracy: 0.7330 - val_loss: 0.6769 - val_accuracy: 0.6992\n",
      "Epoch 3/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5104 - accuracy: 0.7354 - val_loss: 0.6851 - val_accuracy: 0.7189\n",
      "Epoch 4/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5093 - accuracy: 0.7355 - val_loss: 0.7134 - val_accuracy: 0.7271\n",
      "Epoch 5/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5085 - accuracy: 0.7369 - val_loss: 0.7581 - val_accuracy: 0.6699\n",
      "Epoch 6/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5077 - accuracy: 0.7371 - val_loss: 0.7348 - val_accuracy: 0.6797\n",
      "Epoch 7/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5069 - accuracy: 0.7377 - val_loss: 0.7316 - val_accuracy: 0.7106\n",
      "Epoch 8/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5062 - accuracy: 0.7378 - val_loss: 0.6921 - val_accuracy: 0.7083\n",
      "Epoch 9/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5057 - accuracy: 0.7381 - val_loss: 0.6876 - val_accuracy: 0.7194\n",
      "Epoch 10/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5050 - accuracy: 0.7386 - val_loss: 0.7153 - val_accuracy: 0.6941\n",
      "Epoch 11/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5048 - accuracy: 0.7389 - val_loss: 0.6829 - val_accuracy: 0.7295\n",
      "Epoch 12/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5043 - accuracy: 0.7386 - val_loss: 0.7229 - val_accuracy: 0.7026\n",
      "Epoch 13/20\n",
      "4285/4285 [==============================] - 7s 2ms/step - loss: 0.5036 - accuracy: 0.7394 - val_loss: 0.7314 - val_accuracy: 0.6954\n",
      "Epoch 14/20\n",
      "4285/4285 [==============================] - 7s 2ms/step - loss: 0.5031 - accuracy: 0.7395 - val_loss: 0.6799 - val_accuracy: 0.7228\n",
      "Epoch 15/20\n",
      "4285/4285 [==============================] - 6s 2ms/step - loss: 0.5028 - accuracy: 0.7396 - val_loss: 0.7315 - val_accuracy: 0.6880\n",
      "Epoch 16/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5023 - accuracy: 0.7402 - val_loss: 0.7211 - val_accuracy: 0.7129\n",
      "Epoch 17/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5019 - accuracy: 0.7404 - val_loss: 0.6858 - val_accuracy: 0.7119\n",
      "Epoch 18/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5016 - accuracy: 0.7409 - val_loss: 0.7242 - val_accuracy: 0.6917\n",
      "Epoch 19/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5014 - accuracy: 0.7410 - val_loss: 0.7261 - val_accuracy: 0.7018\n",
      "Epoch 20/20\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5007 - accuracy: 0.7419 - val_loss: 0.6873 - val_accuracy: 0.7210\n",
      "Test Loss: 0.46397513151168823\n",
      "Test Accuracy: 0.742152214050293\n",
      "=============================================\n",
      " Epochs: 30\n",
      "Epoch 1/30\n",
      "4285/4285 [==============================] - 7s 1ms/step - loss: 0.5179 - accuracy: 0.7295 - val_loss: 0.7322 - val_accuracy: 0.6901\n",
      "Epoch 2/30\n",
      "4285/4285 [==============================] - 7s 2ms/step - loss: 0.5120 - accuracy: 0.7341 - val_loss: 0.7064 - val_accuracy: 0.7056\n",
      "Epoch 3/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5104 - accuracy: 0.7344 - val_loss: 0.7051 - val_accuracy: 0.7254\n",
      "Epoch 4/30\n",
      "4285/4285 [==============================] - 6s 2ms/step - loss: 0.5092 - accuracy: 0.7364 - val_loss: 0.7426 - val_accuracy: 0.6559\n",
      "Epoch 5/30\n",
      "4285/4285 [==============================] - 7s 2ms/step - loss: 0.5083 - accuracy: 0.7361 - val_loss: 0.6623 - val_accuracy: 0.7398\n",
      "Epoch 6/30\n",
      "4285/4285 [==============================] - 7s 2ms/step - loss: 0.5075 - accuracy: 0.7373 - val_loss: 0.7018 - val_accuracy: 0.7052\n",
      "Epoch 7/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5070 - accuracy: 0.7371 - val_loss: 0.7486 - val_accuracy: 0.6832\n",
      "Epoch 8/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5063 - accuracy: 0.7385 - val_loss: 0.6994 - val_accuracy: 0.6957\n",
      "Epoch 9/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5058 - accuracy: 0.7378 - val_loss: 0.7289 - val_accuracy: 0.6784\n",
      "Epoch 10/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5051 - accuracy: 0.7387 - val_loss: 0.6895 - val_accuracy: 0.7100\n",
      "Epoch 11/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5046 - accuracy: 0.7383 - val_loss: 0.7135 - val_accuracy: 0.7012\n",
      "Epoch 12/30\n",
      "4285/4285 [==============================] - 6s 2ms/step - loss: 0.5043 - accuracy: 0.7393 - val_loss: 0.7370 - val_accuracy: 0.6549\n",
      "Epoch 13/30\n",
      "4285/4285 [==============================] - 8s 2ms/step - loss: 0.5035 - accuracy: 0.7389 - val_loss: 0.7220 - val_accuracy: 0.6940\n",
      "Epoch 14/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5031 - accuracy: 0.7399 - val_loss: 0.7657 - val_accuracy: 0.6510\n",
      "Epoch 15/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5026 - accuracy: 0.7393 - val_loss: 0.7073 - val_accuracy: 0.6894\n",
      "Epoch 16/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5020 - accuracy: 0.7397 - val_loss: 0.7375 - val_accuracy: 0.6737\n",
      "Epoch 17/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5017 - accuracy: 0.7406 - val_loss: 0.7158 - val_accuracy: 0.6939\n",
      "Epoch 18/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5013 - accuracy: 0.7404 - val_loss: 0.6867 - val_accuracy: 0.7112\n",
      "Epoch 19/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5012 - accuracy: 0.7406 - val_loss: 0.7028 - val_accuracy: 0.6840\n",
      "Epoch 20/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5006 - accuracy: 0.7413 - val_loss: 0.6929 - val_accuracy: 0.7137\n",
      "Epoch 21/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5001 - accuracy: 0.7416 - val_loss: 0.7140 - val_accuracy: 0.7029\n",
      "Epoch 22/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.5000 - accuracy: 0.7412 - val_loss: 0.6750 - val_accuracy: 0.7043\n",
      "Epoch 23/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.4997 - accuracy: 0.7417 - val_loss: 0.7415 - val_accuracy: 0.6605\n",
      "Epoch 24/30\n",
      "4285/4285 [==============================] - 6s 2ms/step - loss: 0.4992 - accuracy: 0.7418 - val_loss: 0.6628 - val_accuracy: 0.7169\n",
      "Epoch 25/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.4987 - accuracy: 0.7428 - val_loss: 0.6711 - val_accuracy: 0.7123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.4985 - accuracy: 0.7424 - val_loss: 0.7412 - val_accuracy: 0.6785\n",
      "Epoch 27/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.4983 - accuracy: 0.7432 - val_loss: 0.6981 - val_accuracy: 0.6824\n",
      "Epoch 28/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.4979 - accuracy: 0.7438 - val_loss: 0.7296 - val_accuracy: 0.6823\n",
      "Epoch 29/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.4976 - accuracy: 0.7434 - val_loss: 0.6707 - val_accuracy: 0.7123\n",
      "Epoch 30/30\n",
      "4285/4285 [==============================] - 6s 1ms/step - loss: 0.4974 - accuracy: 0.7441 - val_loss: 0.7006 - val_accuracy: 0.6932\n",
      "Test Loss: 0.45899584889411926\n",
      "Test Accuracy: 0.7491680383682251\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# List of epochs to iterate over\n",
    "epochs_list = [10, 20, 30] \n",
    "\n",
    "# Create empty lists to store results\n",
    "results = []\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    print(f\" Epochs: {epochs}\")\n",
    "\n",
    "    # Initialise a neural network model\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model on the separate test data\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_scaled_70, y_test_70, verbose=0)\n",
    "\n",
    "    # Print metrics for test data\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356b2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d7e9880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10\n",
      "6121/6121 [==============================] - 9s 832us/step\n",
      "983/983 [==============================] - 3s 723us/step\n",
      "6121/6121 [==============================] - 6s 761us/step\n",
      "Training AUC: 0.8090124812350254\n",
      "Test AUC: 0.5\n",
      "Training Accuracy: 0.7504595494373072\n",
      "Test Accuracy: 0.7783359298000191\n",
      "---------------------------------------------\n",
      "Epochs: 20\n",
      "6121/6121 [==============================] - 6s 839us/step\n",
      "983/983 [==============================] - 2s 1ms/step\n",
      "6121/6121 [==============================] - 6s 853us/step\n",
      "Training AUC: 0.8116293352587005\n",
      "Test AUC: 0.5\n",
      "Training Accuracy: 0.7513071628438962\n",
      "Test Accuracy: 0.7783359298000191\n",
      "---------------------------------------------\n",
      "Epochs: 30\n",
      "6121/6121 [==============================] - 6s 799us/step\n",
      "983/983 [==============================] - 2s 759us/step\n",
      "6121/6121 [==============================] - 6s 812us/step\n",
      "Training AUC: 0.8139730665378064\n",
      "Test AUC: 0.499959151995425\n",
      "Training Accuracy: 0.7524611425420232\n",
      "Test Accuracy: 0.7782723428607764\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of epochs to iterate over\n",
    "epochs_list = [10, 20, 30]\n",
    "    \n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_80.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_80[\"PolicyIssued\"]\n",
    "\n",
    "# Train the model on the entire training data using a neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=len(X.columns)))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Loop over epochs\n",
    "for epochs in epochs_list:\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=0)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred_train = np.round(model.predict(X_train)).astype(int)\n",
    "    y_pred_test = np.round(model.predict(X_test_80)).astype(int)\n",
    "\n",
    "    # Calculate Training AUC and Test AUC\n",
    "    train_auc = roc_auc_score(y_train, model.predict(X_train))\n",
    "    test_auc = roc_auc_score(y_test_80, y_pred_test)\n",
    "\n",
    "    # Calculate Training Accuracy and Test Accuracy\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test_80, y_pred_test)\n",
    "\n",
    "    # Print evaluation metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e983c6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10\n",
      "5356/5356 [==============================] - 8s 988us/step\n",
      "1475/1475 [==============================] - 4s 987us/step\n",
      "5356/5356 [==============================] - 7s 763us/step\n",
      "Training AUC: 0.8104333221646629\n",
      "Test AUC: 0.499986383813077\n",
      "Training Accuracy: 0.7508753297075231\n",
      "Test Accuracy: 0.7783123847474512\n",
      "---------------------------------------------\n",
      "Epochs: 20\n",
      "5356/5356 [==============================] - 5s 797us/step\n",
      "1475/1475 [==============================] - 2s 731us/step\n",
      "5356/5356 [==============================] - 5s 784us/step\n",
      "Training AUC: 0.8128551136609363\n",
      "Test AUC: 0.5113831687232941\n",
      "Training Accuracy: 0.7523984033986135\n",
      "Test Accuracy: 0.7677356450963352\n",
      "---------------------------------------------\n",
      "Epochs: 30\n",
      "5356/5356 [==============================] - 6s 905us/step\n",
      "1475/1475 [==============================] - 2s 886us/step\n",
      "5356/5356 [==============================] - 5s 851us/step\n",
      "Training AUC: 0.8164514937889974\n",
      "Test AUC: 0.5005972686100895\n",
      "Training Accuracy: 0.7541315562195093\n",
      "Test Accuracy: 0.22323491383878422\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of epochs to iterate over\n",
    "epochs_list = [10, 20, 30]\n",
    "    \n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X_train = resampled_df_70.drop(\"PolicyIssued\", axis=1)\n",
    "y_train = resampled_df_70[\"PolicyIssued\"]\n",
    "\n",
    "# Train the model on the entire training data using a neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=len(X.columns)))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Loop over epochs\n",
    "for epochs in epochs_list:\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=0)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred_train = np.round(model.predict(X_train)).astype(int)\n",
    "    y_pred_test = np.round(model.predict(X_test_70)).astype(int)\n",
    "\n",
    "    # Calculate Training AUC and Test AUC\n",
    "    train_auc = roc_auc_score(y_train, model.predict(X_train))\n",
    "    test_auc = roc_auc_score(y_test_70, y_pred_test)\n",
    "\n",
    "    # Calculate Training Accuracy and Test Accuracy\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test_70, y_pred_test)\n",
    "\n",
    "    # Print evaluation metrics for training and test data\n",
    "    print(\"Training AUC:\", train_auc)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"---------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
